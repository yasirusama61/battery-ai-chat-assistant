{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857478c7-ee92-4d87-8f5a-146fab1354e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/44.1 kB ? eta -:--:--\n",
      "     ----------------------------------- -- 41.0/44.1 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.1/44.1 kB 434.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yasir\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB 991.0 kB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.1/10.0 MB 991.0 kB/s eta 0:00:11\n",
      "    --------------------------------------- 0.2/10.0 MB 1.1 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/10.0 MB 1.1 MB/s eta 0:00:09\n",
      "    --------------------------------------- 0.2/10.0 MB 1.0 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.3/10.0 MB 1.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.3/10.0 MB 1.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.4/10.0 MB 1.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.5/10.0 MB 1.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.5/10.0 MB 1.2 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.6/10.0 MB 1.1 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.6/10.0 MB 1.2 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.7/10.0 MB 1.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.8/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.8/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.9/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.9/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.1/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.1/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.2/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.4/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.4/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.5/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.5/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.7/10.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.8/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.8/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.9/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.9/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.0/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.0/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.1/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.1/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.2/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.3/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.3/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.4/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.4/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.5/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.5/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.5/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.5/10.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.7/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.0/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.0/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.1/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.2/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.2/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.3/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.3/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.3/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.3/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.4/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.4/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.5/10.0 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 3.5/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.6/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.6/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.7/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.7/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.8/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.8/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.9/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.0/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.0/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.1/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.1/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.3/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.3/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.4/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.6/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.6/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.6/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.7/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.7/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.8/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.9/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.9/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.9/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 5.0/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.0/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.1/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.2/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.2/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.3/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.3/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.3/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.4/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.4/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.5/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.6/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.6/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.6/10.0 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.9/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.9/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.9/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.0/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.1/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.1/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.2/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.2/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.3/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.3/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.4/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.4/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.5/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.5/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.5/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.6/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.6/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.6/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.6/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 6.7/10.0 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.8/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.8/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.9/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.9/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.0/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.0/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.2/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.3/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.4/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.4/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.5/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.6/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.6/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.7/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.7/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.7/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.8/10.0 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.9/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.9/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.0/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.0/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.1/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.1/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.2/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.2/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.3/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.3/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.4/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.5/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.5/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.6/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.8/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.0/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.1/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.1/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.3/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.4/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.6/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.8/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.5 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/447.5 kB 960.0 kB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 122.9/447.5 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 143.4/447.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 204.8/447.5 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 235.5/447.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 286.7/447.5 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 358.4/447.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 419.8/447.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 447.5/447.5 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.3 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/286.3 kB 960.0 kB/s eta 0:00:01\n",
      "   ------------ --------------------------- 92.2/286.3 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 174.1/286.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 204.8/286.3 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 276.5/286.3 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 286.3/286.3 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.4 MB 1.7 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.2/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.4/2.4 MB 1.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.5/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.5/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.5/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.6/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.6/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.6/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.7/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.8/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.9/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.9/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.0/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.1/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.2/2.4 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.2/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.4 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 1.3/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.4/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.5/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.5/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.6/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.7/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.9/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.0/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.0/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.2/2.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.2/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.2 safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "284b8fce-f6c1-4007-b0a3-bbd41081cd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cb0de910a741f482c206c0766fe108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hi! I’m your AI companion. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what can you do?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: what can you do?\n",
      "\n",
      "I'm not sure what you're going to do. I'm not sure what you're going to do.\n",
      "\n",
      "I'm not sure what you're going to do.\n",
      "\n",
      "I'm not sure what you\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  this is good \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: this is good .\")\n",
      "\n",
      "The first thing to do is to make sure that you have a good understanding of the language you are using. If you are using a language that is not English, you will probably be using a language that is not\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # You can switch to \"distilgpt2\" for a smaller version\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "def chatbot_response(prompt, max_length=50):\n",
    "    \"\"\"\n",
    "    Generate a response from the chatbot based on user input.\n",
    "    Args:\n",
    "    - prompt (str): User input text.\n",
    "    - max_length (int): Maximum length of the response.\n",
    "    \n",
    "    Returns:\n",
    "    - str: Chatbot's response.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Chat loop\n",
    "print(\"Chatbot: Hi! I’m your AI companion. Type 'exit' to quit.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    response = chatbot_response(user_input)\n",
    "    print(f\"Chatbot: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c67db0b9-8e41-40e6-b432-aff524a88bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 20.5/232.6 kB 640.0 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 61.4/232.6 kB 812.7 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 81.9/232.6 kB 907.3 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 92.2/232.6 kB 655.4 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 143.4/232.6 kB 652.5 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 194.6/232.6 kB 737.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- 232.6/232.6 kB 835.8 kB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4bd4511-158a-4265-9960-085e9aef7da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file.\n",
    "    Args:\n",
    "    - pdf_path (str): Path to the PDF file.\n",
    "    \n",
    "    Returns:\n",
    "    - str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eed49d6f-78f4-4038-b3c9-0c17046f70f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PDF Text:\n"
     ]
    }
   ],
   "source": [
    "pdf_text = extract_text_from_pdf(\"sample.pdf\")\n",
    "print(\"Extracted PDF Text:\")\n",
    "#print(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba4caaf-63c0-47d0-a1e0-b2b82a1b362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yasir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yasir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yasir\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text:\n",
      " c omprehens review yolo rchitectur comput vision yolo v1toyolo v8and yolona publish journal paper machin learn knowledg extract juan r. terven instituto politecnico nacion cicataqro diana m. cordovaesparza universidad autnoma de quertaro facultad de informtica abstract yolo becom central realtim object detect system robot , driverless car , video monitor applic . present comprehens analysi yolo evolut , examin innov contribut iter origin yolo yolov8 , yolona , yolo transform . start describ standard metric postprocess , discus major chang network architectur train trick model . final , summar essenti lesson yolo develop provid perspect futur , highlight potenti research direct enhanc realtim object detect system . keyword yolo object detect deep learn comput vision 1 introduct realtim object detect emerg critic compon numer applic , span variou field autonom vehicl , robot , video surveil , augment realiti . among differ object detect algorithm , yolo look framework stood remark balanc speed accuraci , enabl rapid reliabl identif object imag . sinc incept , yolo famili evolv multipl iter , build upon previou version address limit enhanc perform see figur 1. paper aim provid comprehens review yolo framework develop , origin yolov1 latest yolov8 , elucid key innov , differ , improv across version . addit yolo framework , field object detect imag process develop sever notabl method . techniqu rcnn regionbas convolut neural network 1 successor , fast rcnn 2 faster rcnn 3 , play pivot role advanc accuraci object detect . method reli twostag process , select search gener region propos , convolut neural network classifi refin region . anoth signific approach singleshot multibox detector ssd 4 , , similar yolo , focus speed effici elimin need separ region propos step . addit , method like mask rnn 5 extend capabl instanc segment , enabl precis object local pixellevel segment . develop , alongsid other retinanet 6 efficientdet 7 , collect contribut diver landscap object detect algorithm . method present uniqu tradeoff speed , accuraci , complex , cater differ applic need comput constraints.arxiv2304.00501v7 cs.cv 4 feb 2024publish journal paper machin learn knowledg extract yolov8 yolona figur 1 timelin yolo version . great review includ 8,9,10. howev , review 8 cover yolov3 , 9 cover yolov4 , leav behind recent develop . paper , differ 10 , show indepth architectur yolo architectur present cover variat , yolox , ppyolo , yolo transform , yolona . paper begin explor foundat concept architectur origin yolo model , set stage subsequ advanc yolo famili . follow , dive refin enhanc introduc version , rang yolov2 yolov8 . improv encompass variou aspect network design , loss function modif , anchor box adapt , input resolut scale . examin develop , aim offer holist understand yolo framework evolut implic object detect . addit discus specif advanc yolo version , paper highlight tradeoff speed accuraci emerg throughout framework develop . underscor import consid context requir specif applic select appropri yolo model . final , envis futur direct yolo framework , touch upon potenti avenu research develop shape ongo progress realtim object detect system . 2 yolo applic across diver field yolo realtim object detect capabl invalu autonom vehicl system , enabl quick identif track variou object vehicl , pedestrian 11,12 , bicycl , obstacl 13,14,15,16. capabl appli numer field , includ action recognit 17 video sequenc surveil 18 , sport analysi 19 , humancomput interact 20. yolo model use agricultur detect classifi crop 21,22 , pest , diseas 23 , assist precis agricultur techniqu autom farm process . also adapt face detect task biometr , secur , facial recognit system 24 , 25. medic field , yolo employ cancer detect 26,27 , skin segment 28 , pill identif 29 , lead improv diagnost accuraci effici treatment process . remot sen , use object detect classif satellit aerial imageri , aid land use map , urban plan , environment monitor 30 , 31 , 32 , 33. secur system integr yolo model realtim monitor analysi video feed , allow rapid detect suspici activ 34 , social distanc , face mask detect 35. model also appli surfac inspect detect defect anomali , enhanc qualiti control manufactur product process 36 , 37 , 38. traffic applic , yolo model util task licens plate detect 39 traffic sign recognit 40 , contribut develop intellig transport system traffic manag solut . employ wildlif detect monitor identifi endang speci biodivers conserv ecosystem manag 41. lastli , yolo wide use robot applic 42,43 object 2publish journal paper machin learn knowledg extract detect drone 44 , 45. figur 2 show bibliometr network visual paper found scopu word yolo titl filter object detect keyword . , manual filter paper relat applic . figur 2 bibliometr network visual main yolo applic creat ? . 3 object detect metric nonmaximum suppress nm averag precis ap , tradit call mean averag precis map , commonli use metric evalu perform object detect model . measur averag precis across categori , provid singl valu compar differ model . coco dataset make distinct ap map . rest paper , refer metric ap . yolov1 yolov2 , dataset util train benchmark pascal voc 2007 , voc 2012 46. howev , yolov3 onward , dataset use microsoft coco common object context 47. ap calcul differ dataset . follow section discus rational behind ap explain comput . 3.1 ap work ? ap metric base precisionrecal metric , handl multipl object categori , defin posit predict use intersect union iou . precis recal precis measur accuraci model posit predict , recal measur proport actual posit case model correctli identifi . often tradeoff precis recal exampl , increas number detect object higher recal result fals posit lower precis . account tradeoff , ap metric incorpor precisionrecal curv plot precis 3publish journal paper machin learn knowledg extract recal differ confid threshold . metric provid balanc ass precis recal consid area precisionrecal curv . handl multipl object categori object detect model must identifi local multipl object categori imag . ap metric address calcul categori averag precis ap separ take mean ap across categori also call mean averag precis . approach ensur model perform evalu categori individu , provid comprehens ass model overal perform . intersect union object detect aim accur local object imag predict bound box . ap metric incorpor intersect union iou measur ass qualiti predict bound box . iou ratio intersect area union area predict bound box ground truth bound box see figur 3. measur overlap ground truth predict bound box . coco benchmark consid multipl iou threshold evalu model perform differ level local accuraci . figur 3 intersect union iou . iou calcul divid intersect two box union box b exampl three differ iou valu differ box locat . 3.2 comput ap ap comput differ voc coco dataset . section , describ comput dataset . voc dataset dataset includ 20 object categori . comput ap voc , follow next step 1.for categori , calcul precisionrecal curv vari confid threshold model predict . 2.calcul categori averag precis ap use interpol 11point sampl precisionrecal curv . 3. comput final averag precis ap take mean ap across 20 categori . microsoft coco dataset dataset includ 80 object categori use complex method calcul ap . instead use 11point interpol , use 101point interpol , i.e. , comput precis 101 recal threshold 0 1 increment 0.01. also , ap obtain averag multipl iou valu instead one , except common ap metric call ap50 , ap singl iou threshold 0.5. step comput ap coco follow 1.for categori , calcul precisionrecal curv vari confid threshold model predict . 4publish journal paper machin learn knowledg extract 2. comput categori averag precis ap use 101recal threshold . 3.calcul ap differ intersect union iou threshold , typic 0.5 0.95 step size 0.05. higher iou threshold requir accur predict consid true posit . 4. iou threshold , take mean ap across 80 categori . 5. final , comput overal ap averag ap valu calcul iou threshold . differ ap calcul make hard directli compar perform object detect model across two dataset . current standard use coco ap due finegrain evalu well model perform differ iou threshold . 3.3 nonmaximum suppress nm nonmaximum suppress nm postprocess techniqu use object detect algorithm reduc number overlap bound box improv overal detect qualiti . object detect algorithm typic gener multipl bound box around object differ confid score . nm filter redund irrelev bound box , keep accur one . algorithm 1 describ procedur . figur 4 show typic output object detect model contain multipl overlap bound box output nm . algorithm 1 nonmaximum suppress algorithm requir set predict bound box b , confid score , iou threshold , confid threshold ensur set filter bound box f 1f 2filter box b bbsbt 3sort box bbi confid score descend order 4while bdo 5 select box bwith highest confid score 6 addbto set final box fff b 7 remov bfrom set box bbb b 8 remain box rinbdo 9 calcul iou bandriouioub , r 10 ifiouthen 11 remov rfrom set box bbb r 12 end 13 end 14end figur 4 nonmaximum suppress nm . show typic output object detect model contain multipl overlap box . b show output nm . readi start describ differ yolo model . 5publish journal paper machin learn knowledg extract 4 yolo look yolo joseph redmon et al . publish cvpr 2016 48. present first time realtim endtoend approach object detect . name yolo stand look , refer fact abl accomplish detect task singl pas network , oppos previou approach either use slide window follow classifi need run hundr thousand time per imag advanc method divid task twostep , first step detect possibl region object region propos second step run classifi propos . also , yolo use straightforward output base regress predict detect output oppos fast rcnn 2 use two separ output , classif probabl regress box coordin . 4.1 yolov1 work ? yolov1 unifi object detect step detect bound box simultan . accomplish , yolo divid input imag ssgrid predict bbound box class , along confid cdiffer class per grid element . bound box predict consist five valu pc , bx , , bh , bw pci confid score box reflect confid model box contain object accur box . bxandbycoordin center box rel grid cell , bhandbwar height width box rel full imag . output yolo tensor ssb5 coption follow nonmaximum suppress nm remov duplic detect . origin yolo paper , author use pascal voc dataset 46 contain 20 class c 20 grid of77 7 2class per grid element b 2 , give 7730output predict . figur 5 show simplifi output vector consid threebythre grid , three class , singl class per grid eight valu . simplifi case , output yolo would 338. yolov1 achiev averag precis ap 63.4 pascal voc2007 dataset . figur 5 yolo output predict . figur depict simplifi yolo model threebythre grid , three class , singl class predict per grid element produc vector eight valu . 6publish journal paper machin learn knowledg extract tabl 1 yolo architectur . architectur compris 24 convolut layer combin 33convolut 11convolut channel reduct . output fulli connect layer gener grid 77with 30 valu grid cell accommod ten bound box coordin 2 box 20 categori . type filter sizestrid output conv 64 77 2 224224 max pool 22 2 112112 conv 192 33 1 112112 max pool 22 2 5656 1conv 128 11 1 5656 conv 256 33 1 5656 conv 256 11 1 5656 conv 512 33 1 5656 max pool 22 2 2828 4conv 256 11 1 2828 conv 512 33 1 2828 conv 512 11 1 2828 conv 1024 33 1 2828 max pool 22 2 1414 2conv 512 11 1 1414 conv 1024 33 1 1414 conv 1024 33 1 1414 conv 1024 33 2 77 conv 1024 33 1 77 conv 1024 33 1 77 fc 4096 4096 dropout 0.5 4096 fc 7730 7 730 4.2 yolov1 architectur yolov1 architectur compris 24 convolut layer follow two fullyconnect layer predict bound box coordin probabl . layer use leaki rectifi linear unit activ 49 except last one use linear activ function . inspir googlenet 50 network network 51 , yolo use 11convolut layer reduc number featur map keep number paramet rel low . activ layer , tabl 1 describ yolov1 architectur . author also introduc lighter model call fast yolo , compos nine convolut layer . 4.3 yolov1 train author pretrain first 20 layer yolo resolut 224224use imagenet dataset 52. , ad last four layer randomli initi weight finetun model pascal voc 2007 , voc 2012 dataset 46 resolut 448448to increas detail accur object detect . augment , author use random scale translat 20 input imag size , well random exposur satur upperend factor 1.5 hsv color space . yolov1 use loss function compos multipl sumsquar error , shown figur 6. loss function , coord 5i scale factor give import bound box predict , noobj 0.5i scale factor decreas import box contain object . first two term loss repres local loss comput error predict bound box locat x , size w , h. note error comput box contain object repres 1obj ij , penal object present grid cell . third fourth loss term repres confid loss third term measur confid error object detect box 1obj ij fourth term measur confid error object detect box 1noobj ij . sinc box 7publish journal paper machin learn knowledg extract empti , loss weight noobj term . final loss compon classif loss measur squar error class condit probabl class object appear cell 1obj i. figur 6 yolo cost function includ local loss bound box coordin , confid loss object presenc absenc , classif loss categori predict accuraci . 4.4 yolov1 strength limit simpl architectur yolo , along novel fullimag oneshot regress , made much faster exist object detector allow realtim perform . howev , yolo perform faster object detector , local error larger compar stateoftheart method fast rcnn 2. three major caus limit 1.it could detect two object class grid cell , limit abil predict nearbi object . 8publish journal paper machin learn knowledg extract 2. struggl predict object aspect ratio seen train data . 3. learn coars object featur due downsampl layer . 5 yolov2 better , faster , stronger yolov2 publish cvpr 2017 53 joseph redmon ali farhadi . includ sever improv origin yolo , make better , keep speed also stronger capabl detect 9000 categori ! . improv follow 1.batch normal convolut layer improv converg act regular reduc overfit . 2.highresolut classifi . like yolov1 , pretrain model imagenet 224224. howev , time , finetun model ten epoch imagenet resolut 448448 , improv network perform higher resolut input . 3.fulli convolut . remov den layer use fulli convolut architectur . 4.use anchor box predict bound box . use set prior box oranchor box , box predefin shape use match prototyp shape object shown figur 7. multipl anchor box defin grid cell , system predict coordin class everi anchor box . size network output proport number anchor box per grid cell . 5.dimens cluster . pick good prior box help network learn predict accur bound box . author ran kmean cluster train bound box find good prior . select five prior box provid good tradeoff recal model complex . 6.direct locat predict . unlik method predict offset 3 , yolov2 follow philosophi predict locat coordin rel grid cell . network predict five bound box cell , five valu tx , ty , tw , th , , toi equival pcfrom yolov1 final bound box coordin obtain shown figur 8 . 7.finnergrain featur . yolov2 , compar yolov1 , remov one pool layer obtain output featur map grid 1313for input imag 416416. yolov2 also use passthrough layer take 2626512featur map reorgan stack adjac featur differ channel instead lose via spatial subsampl . gener 13132048 featur map concaten channel dimens lower resolut 13131024 map obtain 13133072 featur map . see tabl 2 architectur detail . 8.multiscal train . sinc yolov2 use fulli connect layer , input differ size . make yolov2 robust differ input size , author train model randomli , chang input size 320320up 608608 everi ten batch . figur 7 anchor box . yolov2 defin multipl anchor box grid cell . improv , yolov2 achiev averag precis ap 78.6 pascal voc2007 dataset compar 63.4 obtain yolov1 . 5.1 yolov2 architectur backbon architectur use yolov2 call darknet19 , contain 19 convolut layer five max pool layer . similar architectur yolov1 , inspir network network 51 use 11 9publish journal paper machin learn knowledg extract figur 8 bound box predict . box center coordin obtain predict tx , tyvalu pas sigmoid function offset locat grid cell cx , cy . width height final box use prior width pwand height phscale etwandethrespect , twandthar predict yolov2 . convolut 33to reduc number paramet . addit , mention , use batch normal regular help converg . tabl 2 show entir darknet19 backbon object detect head . yolov2 predict five bound box , five valu 20 class use pascal voc dataset . object classif head replac last four convolut layer singl convolut layer 1000 filter , follow global averag pool layer softmax . 5.2 yolo9000 stronger yolov2 author introduc method train joint classif detect paper . use detect label data coco 47 learn bound box coordin classif data imagenet increas number categori detect . train , combin dataset detect train imag use , backpropag detect network , classif train imag use , backpropag classif part architectur . result yolo model capabl detect 9000 categori henc name yolo9000 . 6 yolov3 yolov3 54 publish arxiv 2018 joseph redmon ali farhadi . includ signific chang bigger architectur par stateoftheart keep realtim perform . follow , describ chang respect yolov2 . 1.bound box predict . like yolov2 , network predict four coordin bound box tx , ty , tw , th howev , time , yolov3 predict object score bound box use logist regress . score 1 anchor box highest overlap ground truth 0 rest anchor box . yolov3 , oppos faster rcnn 3 , assign one anchor box ground truth object . also , anchor box assign object , incur classif loss local loss confid loss . 2.class predict . instead use softmax classif , use binari crossentropi train independ logist classifi pose problem multilabel classif . chang allow assign multipl label box , may occur complex dataset 55 overlap label . exampl , object person man . 3.new backbon . yolov3 featur larger featur extractor compos 53 convolut layer residu connect . section 6.1 describ architectur detail . 10publish journal paper machin learn knowledg extract tabl 2 yolov2 architectur . darknet19 backbon layer 1 23 plu detect head compos last four convolut layer passthrough layer reorgan featur 17thoutput 2626512into 13132048 follow concaten 25thlayer . final convolut gener grid 1313with 125 channel accommod 25 predict 5 coordin 20 class five bound box . num type filter sizestrid output 1 convbn 32 33 1 41641632 2 max pool 22 2 20820832 3 convbn 64 33 1 20820864 4 max pool 22 2 10410464 5 convbn 128 33 1 104104128 6 convbn 64 11 1 10410464 7 convbn 128 33 1 104104128 8 max pool 22 2 5252128 9 convbn 256 33 1 5252256 10 convbn 128 11 1 5252128 11 convbn 256 33 1 5252256 12 max pool 22 2 5252256 13 convbn 512 33 1 2626512 14 convbn 256 11 1 2626256 15 convbn 512 33 1 2626512 16 convbn 256 11 1 2626256 17 convbn 512 33 1 2626512 18 max pool 22 2 1313512 19 convbn 1024 33 1 13131024 20 convbn 512 11 1 1313512 21 convbn 1024 33 1 13131024 22 convbn 512 11 1 1313512 23 convbn 1024 33 1 13131024 24 convbn 1024 33 1 13131024 25 convbn 1024 33 1 13131024 26 reorg layer 17 13132048 27 concat 25 26 13133072 28 convbn 1024 33 1 13131024 29 conv 125 11 1 1313125 4.spatial pyramid pool spp although mention paper , author also ad backbon modifi spp block 56 concaten multipl max pool output without subsampl stride 1 , differ kernel size kkwhere k 1,5,9,13allow larger recept field . version call yolov3spp bestperform version improv ap 50bi 2.7 . 5.multiscal predict . similar featur pyramid network 57 , yolov3 predict three box three differ scale . section 6.2 describ multiscal predict mechan detail . 6.bound box prior . like yolov2 , author also use kmean determin bound box prior anchor box . differ yolov2 , use total five prior box per cell , yolov3 , use three prior box three differ scale . 6.1 yolov3 architectur architectur backbon present yolov3 call darknet53 . replac maxpool layer stride convolut ad residu connect . total , contain 53 convolut layer . figur 9 show architectur detail . darknet53 backbon obtain top1 top5 accuraci compar resnet152 almost 2faster . 11publish journal paper machin learn knowledg extract figur 9 yolov3 darknet53 backbon . architectur yolov3 compos 53 convolut layer , batch normal leaki relu activ . also , residu connect connect input 11 convolut across whole network output 33convolut . architectur shown consist backbon includ detect head compos multiscal predict . 6.2 yolov3 multiscal predict besid larger architectur , essenti featur yolov3 multiscal predict , i.e. , predict multipl grid size . help obtain finer detail box significantli improv predict small object , one main weak previou version yolo . multiscal detect architectur shown figur 10 work follow first output mark y1i equival yolov2 output , 1313grid defin output . second output y2i compos concaten output res4 darknet53 output res8 . featur map differ size , i.e.,1313and2626 , upsampl oper concaten . final , use upsampl oper , third output y3concaten 2626featur map 5252featur map . coco dataset 80 categori , scale provid output tensor shape nn34180 nni size featur map grid cell , 3 indic box per cell 4 1 includ four coordin object score . 6.3 yolov3 result yolov3 releas , benchmark object detect chang pascal voc microsoft coco 47. therefor , , yolo evalu m coco dataset . yolov3spp achiev averag precis ap 36.2 ap 50of 60.6 20 fp , achiev stateoftheart time 2faster . 12publish journal paper machin learn knowledg extract figur 10 yolov3 multiscal detect architectur . output darknet53 backbon branch three differ output mark y1 , y2 , y3 , increas resolut . final predict box filter use nonmaximum suppress . cbl convolutionbatchnormleaki relu block compris one convolut layer batch normal leaki relu . re block compris one cbl follow two cbl structur residu connect , shown figur 9 . 7 backbon , neck , head time , architectur object detector start describ three part backbon , neck , head . figur 11 show highlevel backbon , neck , head diagram . backbon respons extract use featur input imag . typic convolut neural network cnn train largescal imag classif task , imagenet . backbon captur hierarch featur differ scale , lowerlevel featur e.g. , edg textur extract earlier layer higherlevel featur e.g. , object part semant inform extract deeper layer . neck intermedi compon connect backbon head . aggreg refin featur extract backbon , often focus enhanc spatial semant inform across differ scale . neck may includ addit convolut layer , featur pyramid network fpn 57 , mechan improv represent featur . head final compon object detector respons make predict base featur provid backbon neck . typic consist one taskspecif subnetwork perform classif , local , , recent , instanc segment pose estim . head process featur neck provid , gener predict object candid . end , postprocess step , nonmaximum suppress nm , filter overlap predict retain confid detect . rest yolo model , describ architectur use backbon , neck , head . 8 yolov4 two year pas , new version yolo . april 2020 alexey bochkovskiy , chienyao wang , hongyuan mark liao releas arxiv paper yolov4 58. first , felt odd differ author present new offici version yolo howev , yolov4 kept yolo philosophi realtim , open sourc , singl shot , darknet framework improv satisfactori commun rapidli embrac version offici yolov4 . 13publish journal paper machin learn knowledg extract figur 11 architectur modern object detector describ backbon , neck , head . backbon , usual convolut neural network cnn , extract vital featur imag differ scale . neck refin featur , enhanc spatial semant inform . lastli , head use refin featur make object detect predict . yolov4 tri find optim balanc experi mani chang categor bagoffreebi bagofspeci . bagoffreebi method chang train strategi increas train cost increas infer time , common data augment . hand , bagofspeci method slightli increas infer cost significantli improv accuraci . exampl method enlarg recept field 56,59,60 , combin featur 61,57,62,63 , postprocess 64,49,65,66 among other . summar main chang yolov4 follow point enhanc architectur bagofspeci bo integr . author tri multipl architectur backbon , resnext50 67 , efficientnetb3 68 , darknet53 . bestperform architectur modif darknet53 crossstag partial connect cspnet 69 , mish activ function 65 backbon see figur 12. neck , use modifi version spatial pyramid pool spp 56 yolov3spp multiscal predict yolov3 , modifi version path aggreg network panet 70 instead fpn well modifi spatial attent modul sam 71. final , detect head , use anchor yolov3 . therefor , model call cspdarknet53panetspp . crossstag partial connect csp ad darknet53 help reduc comput model keep accuraci . spp block , yolov3spp increas recept field without affect infer speed . modifi version panet concaten featur instead ad origin panet paper . integr bagoffreebi bof advanc train approach . apart regular augmenta tion random bright , contrast , scale , crop , flip , rotat , author implement mosaic augment combin four imag singl one allow detect object outsid usual context also reduc need larg minibatch size batch normal . regular , use dropblock 72 work replac dropout 73 convolut neural network well class label smooth 74,75. detector , ad ciou loss 76 cross minibath normal cmbn collect statist entir batch instead singl minibatch regular batch normal 77. selfadversari train sat . make model robust perturb , adversari attack perform input imag creat decept ground truth object imag keep origin label detect correct object . hyperparamet optim genet algorithm . find optim hyperparamet use train , use genet algorithm first 10 period , cosin anneal schedul 78 alter learn rate train . start reduc learn rate slowli , follow quick reduct halfway train process end slight reduct . 14publish journal paper machin learn knowledg extract figur 12 yolov4 architectur object detect . modul diagram cmb convolut batch normal mish activ , cbl convolut batch normal leaki relu , upsampl , spp spatial pyramid pool , panet path aggreg network . diagram inspir 79. tabl 3 list final select bof bo backbon detector . evalu m coco dataset testdev 2017 , yolov4 achiev ap 43.5 ap 50of 65.7 50 fp nvidia v100 . 9 yolov5 yolov5 80 releas coupl month yolov4 2020 glen jocher , founder ceo ultralyt . use mani improv describ yolov4 section develop pytorch instead darknet . yolov5 incorpor ultralyt algorithm call autoanchor . pretrain tool check adjust anchor box illfit dataset train set , imag size . first appli kmean function dataset label gener initi condit genet evolut ge algorithm . ge algorithm evolv anchor 1000 gener default , use ciou loss 76 best possibl recal fit function . figur 13 show detail architectur yolov5 . 9.1 yolov5 architectur backbon modifi cspdarknet53 start stem , stride convolut layer larg window size reduc memori comput cost follow convolut layer extract relev featur 15publish journal paper machin learn knowledg extract tabl 3 yolov4 final select bagoffreebi bof bagofspeci bo . bof method increas perform infer cost longer train time . hand , bo method slightli increas infer cost significantli improv accuraci . backbon detector bagoffreebi bagoffreebi data augment data augment mosaic mosaic cutmix selfadversari train regular ciou loss dropblock cross minibatch normal cmbn class label smooth elimin grid sensit multipl anchor singl ground truth cosin anneal schedul optim hyperparameter random train shape bagofspeci bagofspeci mish activ mish activ crossstag partial connect spatial pyramid pool block multiinput weight residu connect spatial attent modul sam path aggreg network pan distancei nonmaximum suppress input imag . sppf spatial pyramid pool fast layer follow convolut layer process featur variou scale , upsampl layer increas resolut featur map . sppf layer aim speed comput network pool featur differ scale fixeds featur map . convolut follow batch normal bn silu activ 81. neck use sppf modifi csppan , head resembl yolov3 . yolov5 use sever augment mosaic , copi past 82 , random affin , mixup 83 , hsv augment , random horizont flip , well augment albument packag 84. also improv grid sensit make stabl runaway gradient . yolov5 provid five scale version yolov5n nano , yolov5 small , yolov5m medium , yolov5l larg , yolov5x extra larg , width depth convolut modul vari suit specif applic hardwar requir . instanc , yolov5n yolov5 lightweight model target lowresourc devic , yolov5x optim high perform , albeit expens speed . yolov5 releas version time write v7.0 , includ yolov5 version capabl classif instanc segment . yolov5 open sourc activ maintain ultralyt , 250 contributor new improv frequent . yolov5 easi use , train deploy . ultralyt provid mobil version io android mani integr label , train , deploy . evalu m coco dataset testdev 2017 , yolov5x achiev ap 50.7 imag size 640 pixel . use batch size 32 , achiev speed 200 fp nvidia v100 . use larger input size 1536 pixel testtim augment tta , yolov5 achiev ap 55.8 . 10 scaledyolov4 one year yolov4 , author present scaledyolov4 87 cvpr 2021. differ yolov4 , scale yolov4 develop pytorch instead darknet . main novelti introduct scalingup scalingdown techniqu . scale mean produc model increas accuraci expens lower speed hand , scale entail produc model increas speed sacrif accuraci . addit , scaleddown model need le comput power run embed system . scaleddown architectur call yolov4tini design lowend gpu run 46 fp jetson tx2 440 fp rtx2080ti , achiev 22 ap m coco . 16publish journal paper machin learn knowledg extract figur 13 yolov5 architectur . architectur use modifi cspdarknet53 backbon stem , follow convolut layer extract imag featur . spatial pyramid pool fast sppf layer acceler comput pool featur fixeds map . convolut batch normal silu activ . network neck use sppf modifi csppan , head resembl yolov3 . diagram base 85 86. scaledup model architectur call yolov4larg , includ three differ size p5 , p6 , p7 . architectur design cloud gpu achiev stateoftheart perform , surpass previou model 7 , 6 , 88 56 ap m coco . 17publish journal paper machin learn knowledg extract 11 yolor yolor 89 publish arxiv may 2021 research team yolov4 . stand learn one represent . paper , author follow differ approach develop multitask learn approach aim creat singl model variou task e.g. , classif , detect , pose estim learn gener represent use subnetwork creat taskspecif represent . insight tradit joint learn method often lead suboptim featur gener , yolor aim overcom encod implicit knowledg neural network appli multipl task , similar human use past experi approach new problem . result show introduc implicit knowledg neural network benefit task . evalu m coco dataset testdev 2017 , yolor achiev ap 55.4 ap 50of 73.3 30 fp nvidia v100 . 12 yolox yolox 90 publish arxiv juli 2021 megvii technolog . develop pytorch use yolov3 ultralyt start point , five princip chang anchorfre architectur , multipl posit , decoupl head , advanc label assign , strong augment . achiev stateoftheart result 2021 optim balanc speed accuraci 50.1 ap 68.9 fp tesla v100 . follow , describ five main chang yolox respect yolov3 1.anchorfre . sinc yolov2 , subsequ yolo version anchorbas detector . yolox , inspir anchorfre stateoftheart object detector cornernet 91 , centernet 92 , fco 93 , return anchorfre architectur simplifi train decod process . anchorfre increas ap 0.9 point concern yolov3 baselin . 2.multi posit . compens larg imbal lack anchor produc , author use center sampl 93 assign center 33area posit . approach increas ap 2.1 point . 3.decoupl head . 94,95 , shown could misalign classif confid local accuraci . due , yolox separ two two head shown fig . 14 , one classif task regress task improv ap 1.1 point speed model converg . 4.advanc label assign . 96 , shown ground truth label assign could ambigu box multipl object overlap formul assign procedur optim transport ot problem . yolox , inspir work , propos simplifi version call simota . chang increas ap 2.3 point . 5.strong augment . yolox use mixup 83 mosaic augment . author found imagenet pretrain longer benefici use augment . strong augment increas ap 2.4 point . 13 yolov6 yolov6 97 publish arxiv septemb 2022 meituan vision ai depart . network design consist effici backbon repvgg cspstackrep block , pan topolog neck , effici decoupl head hybridchannel strategi . addit , paper introduc enhanc quantiz techniqu use posttrain quantiz channelwis distil , result faster accur detector . overal , yolov6 outperform previou stateoftheart model accuraci speed metric , yolov5 , yolox , ppyolo . figur 15 show detail architectur yolov6 . main novelti model summar 1.a new backbon base repvgg 98 call efficientrep use higher parallel previou yolo backbon . neck , use pan 70 enhanc repblock 98 cspstackrep 69 block larger model . follow yolox , develop effici decoupl head . 2.label assign use task align learn approach introduc tood 100 . 18publish journal paper machin learn knowledg extract figur 14 differ yolov3 head yolox decoupl head . level fpn , use a11convolut layer reduc featur channel 256 ad two parallel branch two 33 convolut layer class confid classif local regress task . iou branch ad regress head . 3.new classif regress loss . use classif varifoc loss 101 siou 102giou 103 regress loss . 4.a selfdistil strategi regress classif task . 5.a quantiz scheme detect use repoptim 104 channelwis distil 105 help achiev faster detector . author provid eight scale model , yolov6n yolov6l6 . evalu m coco dataset testdev 2017 , largest model , achiev ap 57.2 around 29 fp nvidia tesla t4 . 14 yolov7 yolov7 106 publish arxiv juli 2022 author yolov4 yolor . time , surpass known object detector speed accuraci rang 5 fp 160 fp . like yolov4 , train use m coco dataset without pretrain backbon . yolov7 propos coupl architectur chang seri bagoffreebi , increas accuraci without affect infer speed , train time . figur 16 show detail architectur yolov7 . architectur chang yolov7 extend effici layer aggreg network eelan . elan 108 strategi allow deep model learn converg effici control shortest longest gradient path . yolov7 propos eelan work model unlimit stack comput block . eelan combin featur differ group shuffl merg cardin enhanc network learn without destroy origin gradient path . model scale concatenationbas model . scale gener model differ size adjust model attribut . architectur yolov7 concatenationbas architectur standard scale techniqu , depth scale , caus ratio chang input channel output channel transit layer , turn , lead decreas hardwar usag model . yolov7 propos new strategi scale concatenationbas model depth width block scale factor maintain optim structur model . bagoffreebi use yolov7 includ plan reparameter convolut . like yolov6 , architectur yolov7 also inspir reparameter convolut repconv 98. howev , found ident connect repconv 19publish journal paper machin learn knowledg extract figur 15 yolov6 architectur . architectur use new backbon repvgg block 98. spatial pyramid pool fast sppf conv modul similar yolov5 . howev , yolov6 use decoupl head . diagram base 99. destroy residu resnet 61 concaten densenet 109. reason , remov ident connect call repconvn . coars label assign auxiliari head fine label assign lead head . lead head respons final output , auxiliari head assist train . batch normal convbnactiv . integr mean varianc batch normal bia weight convolut layer infer stage . implicit knowledg inspir yolor 89. exponenti move averag final infer model . 14.1 comparison yolov4 yolor section , highlight enhanc yolov7 compar previou yolo model develop author . compar yolov4 , yolov7 achiev 75 reduct paramet 36 reduct comput simultan improv averag precis ap 1.5. contrast yolov4tini , yolov7tini manag reduc paramet comput 39 49 , respec tive , maintain ap . lastli , compar yolor , yolov7 reduc number paramet comput 43 15 , respect , along slight 0.4 increas ap . evalu m coco dataset testdev 2017 , yolov7e6 achiev ap 55.9 ap 50of 73.5 input size 1280 pixel speed 50 fp nvidia v100 . 20publish journal paper machin learn knowledg extract figur 16 yolov7 architectur . chang architectur includ elan block combin featur differ group shuffl merg cardin enhanc model learn modifi repvgg without ident connect . diagram base 107 . 15 damoyolo damoyolo 110 publish arxiv novemb 2022 alibaba group . inspir current technolog , damoyolo includ follow 1.a neural architectur search na . use method call maena 111 develop alibaba find effici architectur automat . 2.a larg neck . inspir giraffedet 112 , cspnet 69 , elan 108 , author design neck work realtim call efficientrepgfpn . 3.a small head . author found larg neck small neck yield better perform , left one linear layer classif one regress . call approach zerohead . 4.alignedota label assign . dynam label assign method , ota 96 tood 100 , gain popular due signific improv static method . howev , misalign classif regress remain problem , partli imbal classif regress loss . address issu , alignota method introduc focal loss 6 classif cost use iou predict ground truth box soft label , enabl select align sampl target solv problem global perspect . 5.knowledg distil . propos strategi consist two stage teacher guid student first stage student finetun independ second stage . addit , incorpor two enhanc distil approach align modul , adapt student featur resolut teacher , channelwis dynam temperatur , normal teacher student featur reduc impact real valu differ . author gener scale model name damoyolotinysmallmedium , best model achiev ap 50.0 233 fp nvidia v100 . 16 yolov8 yolov8 113 releas januari 2023 ultralyt , compani develop yolov5 . yolov8 provid five scale version yolov8n nano , yolov8 small , yolov8m medium , yolov8l larg yolov8x 21publish journal paper machin learn knowledg extract extra larg . yolov8 support multipl vision task object detect , segment , pose estim , track , classif . 16.1 yolov8 architectur figur 17 show detail architectur yolov8 . yolov8 use similar backbon yolov5 chang csplayer , call c2f modul . c2f modul crossstag partial bottleneck two convolut combin highlevel featur contextu inform improv detect accuraci . yolov8 use anchorfre model decoupl head independ process object , classif , regress task . design allow branch focu task improv model overal accuraci . output layer yolov8 , use sigmoid function activ function object score , repres probabl bound box contain object . use softmax function class probabl , repres object probabl belong possibl class . yolov8 use ciou 76 dfl 114 loss function bound box loss binari crossentropi classif loss . loss improv object detect perform , particularli deal smaller object . yolov8 also provid semant segment model call yolov8seg model . backbon cspdarknet53 featur extractor , follow c2f modul instead tradit yolo neck architectur . c2f modul follow two segment head , learn predict semant segment mask input imag . model similar detect head yolov8 , consist five detect modul predict layer . yolov8seg model achiev stateoftheart result variou object detect semant segment benchmark maintain high speed effici . yolov8 run command line interfac cli , also instal pip packag . addit , come multipl integr label , train , deploy . evalu m coco dataset testdev 2017 , yolov8x achiev ap 53.9 imag size 640 pixel compar 50.7 yolov5 input size speed 280 fp nvidia a100 tensorrt . 17 ppyolo , ppyolov2 , ppyolo ppyolo model grow parallel yolo model describ . howev , decid group singl section began yolov3 gradual improv upon previou ppyolo version . nevertheless , model influenti evolut yolo . ppyolo 88 similar yolov4 yolov5 base yolov3 . publish arxiv juli 2020 research baidu inc. author use paddlepaddl 116 deep learn platform , henc ppname . follow trend seen start yolov4 , ppyolo ad ten exist trick improv detector accuraci , keep speed unchang . accord author , paper intend introduc novel object detector show build better detector step step . trick ppyolo use differ one use yolov4 , one overlap use differ implement . chang ppyolo concern yolov3 1.a resnet50vd backbon replac darknet53 backbon architectur augment de formabl convolut 117 last stage distil pretrain model , higher classif accuraci imagenet . architectur call resnet5vddcn . 2.a larger batch size improv train stabil , went 64 192 , along updat train schedul learn rate . 3.maintain move averag train paramet use instead final train valu . 4.dropblock appli fpn . 5.an iou loss ad anoth branch along l1loss bound box regress . 6.an iou predict branch ad measur local accuraci along iou awar loss . infer , yolov3 multipli classif probabl object score comput final detect , ppyolo also multipli predict iou consid local accuraci . 7.grid sensit approach similar yolov4 use improv bound box center predict grid boundari . 8.matrix nm 118 use , run parallel make faster tradit nm . 22publish journal paper machin learn knowledg extract figur 17 yolov8 architectur . architectur use modifi cspdarknet53 backbon . c2f modul replac csplayer use yolov5 . spatial pyramid pool fast sppf layer acceler comput pool featur fixeds map . convolut batch normal silu activ . head decoupl process object , classif , regress task independ . diagram base 115 . 9.coordconv 119 use 11convolut fpn , first convolut layer detect head . coordconv allow network learn translat invari improv detect local . 10.spatial pyramid pool use top featur map increas recept field backbon . 17.1 ppyolo augment preprocess ppyolo use follow augment preprocess 1. mixup train 83 weight sampl beta , distribut 1.5and 1.5 . 23publish journal paper machin learn knowledg extract 2. random color distort . 3. random expand . 4. random crop random flip probabl 0.5 . 5.rgb channel zscore normal mean 0.485,0.456,0.406 standard deviat 0.229,0.224,0.225 . 6. multipl imag size evenli drawn 320 , 352 , 384 , 416 , 448 , 480 , 512 , 544 , 576 , 608. evalu m coco dataset testdev 2017 , ppyolo achiev ap 45.9 ap 50of 65.2 73 fp nvidia v100 . 17.2 ppyolov2 ppyolov2 120 publish arxiv april 2021 ad four refin ppyolo increas perform 45.9 ap 49.5 ap 69 fp nvidia v100 . chang ppyolov2 concern ppyolo follow 1.backbon chang resnet50 resnet101 . 2.path aggreg network pan instead fpn similar yolov4 . 3.mish activ function . unlik yolov4 yolov5 , appli mish activ function detect neck keep backbon unchang relu . 4.larger input size help increas perform small object . expand largest input size 608 768 reduc batch size 24 12 imag per gpu . input size evenli drawn 320 , 352 , 384 , 416 , 448 , 480 , 512 , 544 , 576 , 608 , 640 , 672 , 704 , 736 , 768 . 5.a modifi iou awar branch . modifi calcul iou awar loss calcul use soft label format instead soft weight format . 17.3 ppyolo ppyolo 121 publish arxiv march 2022. ad improv upon ppyolov2 achiev perform 51.4 ap 78.1 fp nvidia v100 . figur 18 show detail architectur diagram . main chang ppyolo concern ppyolov2 1.anchorfre . follow time trend driven work 93,92,91,90 , ppyolo use anchorfre architectur . 2.new backbon neck . inspir treenet 122 , author modifi architectur backbon neck represblock combin residu den connect . 3.task align learn tal . yolox first bring problem task misalign , classif confid locat accuraci agre case . reduc problem , ppyolo implement tal propos tood 100 , includ dynam label assign combin taskalign loss . 4.effici taskalign head ethead . differ yolox classif locat head decoupl , ppyolo instead use singl head base tood improv speed accuraci . 5.varifoc vfl distribut focal loss dfl . vfl 101 weight loss posit sampl use target score , give higher weight high iou . priorit highqual sampl train . similarli , use iouawar classif score iac target , allow joint learn classif local qualiti , lead consist train infer . hand , dfl 114 extend focal loss discret continu label , enabl success optim improv represent combin qualiti estim class predict . allow accur depict flexibl distribut real data , elimin risk inconsist . like previou yolo version , author gener multipl scale model vari width depth backbon neck . model call ppyolo small , ppyoloem medium , ppyoloel larg , ppyoloex extra larg . 24publish journal paper machin learn knowledg extract figur 18 ppyolo architectur . backbon base csprepresnet , neck use path aggreg network , head use e layer form effici taskalign head ethead . diagram base 123 . 18 yolona yolona 124 releas may 2023 deci , compani develop productiongrad model tool build , optim , deploy deep learn model . yolona design detect small object , improv local accuraci , enhanc performancepercomput ratio , make suitabl realtim edgedevic applic . addit , opensourc architectur avail research use . novelti yolona includ follow quantiz awar modul 125 call qsp qci combin reparameter 8bit quantiz minim accuraci loss posttrain quantiz . automat architectur design use autonac , deci proprietari na technolog . hybrid quantiz method select quantiz certain part model balanc latenc accuraci instead standard quantiz , layer affect . pretrain regimen automat label data , selfdistil , larg dataset . autonac system , instrument creat yolona , versatil accommod task , specif data , environ make infer , set perform goal . assist user identifi suitabl structur offer perfect blend precis infer speed particular use . technolog consid data hardwar element involv infer process , compil quantiz . addit , repvgg block incorpor model architectur na process compat posttrain quantiz ptq . gener three architectur vari depth posit qsp qci block yolonass , yolonasm , yolonasl , , l small , medium , larg , respect . figur 19 show model architectur yolonasl . 25publish journal paper machin learn knowledg extract figur 19 yolona architectur . architectur found automat via neural architectur search na system call autonac balanc latenc vs. throughput . gener three architectur call yolonass small , yolonasm medium , yolonasl larg , vari depth posit qsp qci block . figur show yolonasl architectur . model pretrain objects365 126 , contain two million imag 365 categori , coco dataset use gener pseudolabel . final , model train origin 118k train imag coco dataset . write , three yolona model releas fp32 , fp16 , int8 precis , achiev ap 52.2 m coco 16bit precis . 19 yolo transform rise transform 127 take deep learn task languag audio process vision , natur transform yolo combin . one first attempt use transform object detect look one sequenc yolo 128 , turn pretrain vision transfom vit 129 imag classif object detect , achiev 42.0 ap m coco dataset . chang 26publish journal paper machin learn knowledg extract made vit two 1 replac one cl token use classif one hundr det token detect , 2 replac imag classif loss vit bipartit match loss similar endtoend object detect transform 130. figur 20 vityolo architectur . backbon mhsadarknet combin multihead selfattent block mhsa dark block crossstag partial connect block cspdark block . neck use bifpn aggreg featur differ backbon level , head compris five multiscal detect head . mani work combin transform yolorel architectur tailor specif applic . exampl , zhang et al . 131 , motiv robust vision transform occlus , perturb , domain shift , propos vityolo , hybrid architectur combin cspdarknet 58 multihead selfattent mhsadarknet backbon along bidirect featur pyramid network bifpn 7 neck multiscal detect head like yolov3 . specif use case object detect drone imag . figur 20 show detail architectur vityolo . msftyolo 132 add transformerbas modul backbon detect head intend detect defect steel surfac . nrtyolo 133 nest residu transform tri address problem tini object remot sen imag . ad extra predict head , featur fusion layer , residu transform modul , nrtyolo improv yolov5l 5.4 dota data set 134. remot sen applic , yolosd 135 tri improv detect accuraci small ship synthet apertur radar sar imag . start yolox 90 coupl multiscal convolut msc improv 27publish journal paper machin learn knowledg extract tabl 4 summari yolo architectur . metric report yolo yolov2 voc2007 , rest report coco2017 . nasyolo model report 16bit precis . version date anchor framework backbon ap yolo 2015 darknet darknet24 63.4 yolov2 2016 ye darknet darknet24 78.6 yolov3 2018 ye darknet darknet53 33.0 yolov4 2020 ye darknet cspdarknet53 43.5 yolov5 2020 ye pytorch yolov5cspdarknet 55.8 ppyolo 2020 ye paddlepaddl resnet50vd 45.9 scaledyolov4 2021 ye pytorch cspdarknet 56.0 ppyolov2 2021 ye paddlepaddl resnet101vd 50.3 yolor 2021 ye pytorch cspdarknet 55.4 yolox 2021 pytorch yoloxcspdarknet 51.2 ppyolo 2022 paddlepaddl csprepresnet 54.7 yolov6 2022 pytorch efficientrep 52.5 yolov7 2022 pytorch yolov7backbon 56.8 damoyolo 2022 pytorch maena 50.0 yolov8 2023 pytorch yolov8cspdarknet 53.9 yolona 2023 pytorch na 52.2 detect differ scale featur transform modul captur global featur . author show chang improv accuraci yolosd compar yolox hrsid dataset 136. anoth interest attempt combin yolo detect transform detr 130 case deyo 137 compris two stage yolov5bas model follow detrlik model . first stage gener highqual queri anchor input second stage . result show faster converg time better perform detr , achiev 52.1 ap coco detect benchmark . 20 discus paper examin 16 yolo version , rang origin yolo model recent yolona . tabl 4 provid overview yolo version discus . tabl , identifi sever key pattern anchor origin yolo model rel simpl employ anchor , stateofth art reli twostag detector anchor . yolov2 incorpor anchor , lead improv bound box predict accuraci . trend persist five year yolox introduc anchorless approach achiev stateoftheart result . sinc , subsequ yolo version abandon use anchor . framework initi , yolo develop use darknet framework , subsequ version follow suit . howev , ultralyt port yolov3 pytorch , remain yolo version develop use pytorch , lead surg enhanc . anoth deep learn languag util paddlepaddl , opensourc framework initi develop baidu . backbon backbon architectur yolo model undergon signific chang time . start darknet architectur , compris simpl convolut max pool layer , later model incorpor crossstag partial connect csp yolov4 , reparameter yolov6 yolov7 , neural architectur search damoyolo yolona . perform perform yolo model improv time , worth note often priorit balanc speed accuraci rather sole focus accuraci . tradeoff essenti yolo framework , allow realtim object detect across variou applic . 20.1 tradeoff speed accuraci yolo famili object detect model consist focus balanc speed accuraci , aim deliv realtim perform without sacrif qualiti detect result . yolo framework evolv variou iter , tradeoff recur theme , version seek optim compet object differ . origin yolo model , primari focu achiev highspe object 28publish journal paper machin learn knowledg extract detect . model util singl convolut neural network cnn directli predict object locat class input imag , enabl realtim process . howev , emphasi speed led compromis accuraci , mainli deal small object object overlap bound box . subsequ yolo version introduc refin enhanc address limit maintain framework realtim capabl . instanc , yolov2 yolo9000 introduc anchor box passthrough layer improv local object , result higher accuraci . addit , yolov3 enhanc model perform employ multiscal featur extract architectur , allow better object detect across variou scale . tradeoff speed accuraci becam nuanc yolo framework evolv . model like yolov4 yolov5 introduc innov , new network backbon , improv data augment techniqu , optim train strategi . develop led signific gain accuraci without drastic affect model realtim perform . yolov5 , offici yolo model finetun tradeoff speed accuraci , offer differ model scale suit specif applic hardwar requir . instanc , version often provid lightweight model optim edg devic , trade accuraci reduc comput complex faster process time . figur 21 138 show comparison differ model scale yolov5 yolov8 . figur present compar analysi differ version yolo model term complex perform . left graph plot number paramet million mean averag precis map coco valid set , rang iou threshold 50 95. illustr clear trend increas number paramet enhanc model accuraci . model includ variou scale indic nnano , small , mmedium , llarg , xextralarg . right graph contrast infer latenc nvidia a100 gpu , util tensorrt fp16 , map perform metric . , tradeoff infer speed detect accuraci evid . lower latenc valu , indic faster model infer , typic result reduc accuraci . convers , model higher latenc tend achiev better perform coco map metric . relationship pivot applic realtim process crucial , choic model influenc requir balanc speed accuraci . figur 21 perform comparison yolo object detect model . left plot illustr relationship model complex measur number paramet detect accuraci coco map5095 . right plot show tradeoff infer speed latenc a100 tensorrt fp16 accuraci model . model version repres distinct color , marker indic size variant nano toextra . plot taken 138 . 21 futur yolo yolo framework continu evolv , anticip follow trend possibl shape futur develop 29publish journal paper machin learn knowledg extract incorpor latest techniqu . research develop continu refin yolo architectur leverag stateoftheart method deep learn , data augment , train techniqu . ongo innov like improv model perform , robust , effici . benchmark evolut . current benchmark evalu object detect model , coco 2017 , may eventu replac advanc challeng benchmark . mirror transit voc 2007 benchmark use first two yolo version , reflect need demand benchmark model grow sophist accur . prolifer yolo model applic . yolo framework progress , expect wit increas number yolo model releas year , along correspond expans applic . framework becom versatil power , like employ vari domain , home applianc devic autonom car . expans new domain . yolo model potenti expand beyond object detect segment , explor domain object track video 3d keypoint estim . anticip yolo model transit multimod framework , incorpor vision languag , video , sound process . model evolv , may serv foundat innov solut cater broader spectrum comput vision multimedia task . adapt diver hardwar . yolo model span hardwar platform , iot devic high perform comput cluster . adapt enabl deploy yolo model variou context , depend applic requir constraint . addit , tailor model suit differ hardwar specif , yolo made access effect user industri . 22 acknowledg thank nation council scienc technolog conacyt support nation research system sni . refer 1r . girshick , j. donahu , t. darrel , j. malik , rich featur hierarchi accur object detect semant segment , proceed ieee confer comput vision pattern recognit , pp . 580587 , 2014 . 2r . girshick , fast rcnn , proceed ieee intern confer comput vision , pp . 14401448 , 2015 . 3 . ren , k. , r. girshick , j. sun , faster rcnn toward realtim object detect region propos network , advanc neural inform process system , vol . 28 , 2015 . 4w . liu , d. anguelov , d. erhan , c. szegedi , s. reed , c.i . fu , a. c. berg , ssd singl shot multibox detector , comput visioneccv 2016 14th european confer , amsterdam , netherland , octob 1114 , 2016 , proceed , part 14 , pp . 2137 , springer , 2016 . 5k . , g. gkioxari , p. dollr , r. girshick , mask rcnn , proceed ieee intern confer comput vision , pp . 29612969 , 2017 . 6t.i . lin , p. goyal , r. girshick , k. , p. dollr , focal loss den object detect , proceed ieee intern confer comput vision , pp . 29802988 , 2017 . 7m . tan , r. pang , q. v . le , efficientdet scalabl effici object detect , proceed ieeecvf confer comput vision pattern recognit , pp . 1078110790 , 2020 . 8b . bhavya sree , v . yashwanth bharadwaj , n. neelima , intercompar survey stateoftheart detectorsrcnn , yolo , ssd , intellig manufactur energi sustain proceed icim 2020 , pp . 475483 , springer , 2021 . 9t . diwan , g. anirudh , j. v . tembhurn , object detect use yolo challeng , architectur successor , dataset applic , multimedia tool applic , vol . 82 , . 6 , pp . 92439275 , 2023 . 10 m. hussain , yolov1 yolov8 , rise yolo complementari natur toward digit manufactur industri defect detect , machin , vol . 11 , . 7 , p. 677 , 2023 . 11 w. lan , j. dang , . wang , s. wang , pedestrian detect base yolo network model , 2018 ieee intern confer mechatron autom icma , pp . 15471551 , ieee , 2018 . 30publish journal paper machin learn knowledg extract 12 w.i . hsu w.i . lin , adapt fusion multiscal yolo pedestrian detect , ieee access , vol . 9 , pp . 110063110073 , 2021 . 13 a. benjumea , i. teeti , f. cuzzolin , a. bradley , yoloz improv small object detect yolov5 autonom vehicl , arxiv preprint arxiv2112.11798 , 2021 . 14 n. m. a. a. dazle , s. a. khalil , s. abdulrahman , s. mutalib , object detect autonom vehicl sensorbas technolog use yolo , intern journal intellig system applic engin , vol . 10 , . 1 , pp . 129134 , 2022 . 15 s. liang , h. wu , l. zhen , q. hua , s. garg , g. kaddoum , m. m. hassan , k. yu , edg yolo realtim intellig object detect system base edgecloud cooper autonom vehicl , ieee transact intellig transport system , vol . 23 , . 12 , pp . 2534525360 , 2022 . 16 q. li , x. ding , x. wang , l. chen , j. son , j.i . song , detect identif move object busi traffic road base yolo v4 , journal institut internet , broadcast commun , vol . 21 , . 1 , pp . 141148 , 2021 . 17 s. shind , a. kothari , v . gupta , yolo base human action recognit local , procedia comput scienc , vol . 133 , pp . 831838 , 2018 . 18 a. h. ashraf , m. imran , a. m. qahtani , a. alsufyani , o. almutiri , a. mahmood , m. attiqu , m. habib , weapon detect secur video surveil use cnn yolov5 , cmccomput . mater . contin , vol . 70 , pp . 27612775 , 2022 . 19 . zheng h. zhang , video analysi sport lightweight object detect network background sport industri develop , comput intellig neurosci , vol . 2022 , 2022 . 20 h. , t. celik , h. li , feryolo detect classif base facial express , imag graphic 11th intern confer , icig 2021 , haikou , china , august 68 , 2021 , proceed , part 11 , pp . 2839 , springer , 2021 . 21 . tian , g. yang , z. wang , h. wang , e. li , z. liang , appl detect differ growth stage orchard use improv yolov3 model , comput electron agricultur , vol . 157 , pp . 417426 , 2019 . 22 d. wu , s. lv , m. jiang , h. song , use channel pruningbas yolo v4 deep learn algorithm realtim accur detect appl flower natur environ , comput electron agricultur , vol . 178 , p. 105742 , 2020 . 23 m. lippi , n. bonucci , r. f. carpio , m. contarini , s. speranza , a. gasparri , yolobas pest detect system precis agricultur , 2021 29th mediterranean confer control autom med , pp . 342347 , ieee , 2021 . 24 w. yang z. jiachun , realtim face detect base yolo , 2018 1st ieee intern confer knowledg innov invent ickii , pp . 221224 , ieee , 2018 . 25 w. chen , h. huang , s. peng , c. zhou , c. zhang , yolofac realtim face detector , visual comput , vol . 37 , pp . 805813 , 2021 . 26 m. a. almasni , m. a. alantari , j.m . park , g. gi , t.i . kim , p. rivera , e. valarezo , m.t . choi , s.m . han , t. . kim , simultan detect classif breast mass digit mammogram via deep learn yolobas cad system , comput method program biomedicin , vol . 157 , pp . 8594 , 2018 . 27 . nie , p. sommella , m. onil , c. liguori , j. lundgren , automat detect melanoma yolo deep convolut neural network , 2019 ehealth bioengin confer ehb , pp . 14 , ieee , 2019 . 28 h. m. nver e. ayan , skin lesion segment dermoscop imag combin yolo grabcut algorithm , diagnost , vol . 9 , . 3 , p. 72 , 2019 . 29 l. tan , t. huangfu , l. wu , w. chen , comparison retinanet , ssd , yolo v3 realtim pill identif , bmc medic informat decis make , vol . 21 , pp . 111 , 2021 . 30 l. cheng , j. li , p. duan , m. wang , small attent yolo model landslid detect satellit remot sen imag , landslid , vol . 18 , . 8 , pp . 27512765 , 2021 . 31 m.t . pham , l. courtrai , c. friguet , s. lefvr , a. baussard , yolofin onestag detector small object variou background remot sen imag , remot sen , vol . 12 , . 15 , p. 2501 , 2020 . 32 . qing , w. liu , l. feng , w. gao , improv yolo network freeangl remot sen target detect , remot sen , vol . 13 , . 11 , p. 2171 , 2021 . 31publish journal paper machin learn knowledg extract 33 z. zakria , j. deng , r. kumar , m. s. khokhar , j. cai , j. kumar , multiscal direct target detect remot sen imag via modifi yolov4 , ieee journal select topic appli earth observ remot sen , vol . 15 , pp . 10391048 , 2022 . 34 p. kumar , s. narasimha swami , p. kumar , g. purohit , k. s. raju , realtim , yolobas intellig surveil monitor system use jetson tx2 , data analyt manag proceed icdam , pp . 461471 , springer , 2021 . 35 k. bhambani , t. jain , k. a. sultanpur , realtim face mask social distanc violat detect system use yolo , 2020 ieee bangalor humanitarian technolog confer bhtc , pp . 16 , ieee , 2020 . 36 j. li , z. su , j. geng , . yin , realtim detect steel strip surfac defect base improv yolo detect network , ifacpapersonlin , vol . 51 , . 21 , pp . 7681 , 2018 . 37 e. n. ukhwah , e. m. yuniarno , . k. suprapto , asphalt pavement pothol detect use deep learn method base yolo neural network , 2019 intern seminar intellig technolog applic isitia , pp . 3540 , ieee , 2019 . 38 . du , n. pan , z. xu , f. deng , . shen , h. kang , pavement distress detect classif base yolo network , intern journal pavement engin , vol . 22 , . 13 , pp . 16591672 , 2021 . 39 r.c . chen et al . , automat licens plate recognit via slidingwindow darknetyolo deep learn , imag vision comput , vol . 87 , pp . 4756 , 2019 . 40 c. dewi , r.c . chen , x. jiang , h. yu , deep convolut neural network enhanc traffic sign recognit develop yolo v4 , multimedia tool applic , vol . 81 , . 26 , pp . 3782137845 , 2022 . 41 a. m. roy , j. bhaduri , t. kumar , k. raj , wildectyolo effici robust comput visionbas accur object local model autom endang wildlif detect , ecolog informat , vol . 75 , p. 101919 , 2023 . 42 s. kulik a. shtanko , experi neural net object detect system yolo small train dataset intellig robot , advanc technolog robot intellig system proceed itr 2019 , pp . 157162 , springer , 2020 . 43 d. h. do rei , d. welfer , m. a. de souza leit cuadro , d. f. t. gamarra , mobil robot navig use object recognit softwar rgbd imag yolo algorithm , appli artifici intellig , vol . 33 , . 14 , pp . 12901305 , 2019 . 44 o. sahin s. ozer , yolodron improv yolo architectur object detect drone imag , 2021 44th intern confer telecommun signal process tsp , pp . 361365 , ieee , 2021 . 45 c. chen , z. zheng , t. xu , s. guo , s. feng , w. yao , . lan , yolobas uav technolog review research applic , drone , vol . 7 , . 3 , p. 190 , 2023 . 46 m. everingham , l. van gool , c. k. william , j. winn , a. zisserman , pascal visual object class voc challeng , intern journal comput vision , vol . 88 , . 2 , pp . 303338 , 2010 . 47 t.i . lin , m. mair , s. belongi , j. hay , p. perona , d. ramanan , p. dollr , c. l. zitnick , microsoft coco common object context , european confer comput vision , pp . 740755 , springer , 2014 . 48 j. redmon , s. divvala , r. girshick , a. farhadi , look unifi , realtim object detect , proceed ieee confer comput vision pattern recognit , pp . 779788 , 2016 . 49 a. l. maa , a. . hannun , a. . ng , et al . , rectifi nonlinear improv neural network acoust model , proc . icml , vol . 30 , p. 3 , atlanta , georgia , usa , 2013 . 50 c. szegedi , w. liu , . jia , p. sermanet , s. reed , d. anguelov , d. erhan , v . vanhouck , a. rabinovich , go deeper convolut , proceed ieee confer comput vision pattern recognit , pp . 19 , 2015 . 51 m. lin , q. chen , s. yan , network network , arxiv preprint arxiv1312.4400 , 2013 . 52 o. russakovski , j. deng , h. su , j. kraus , s. satheesh , s. , z. huang , a. karpathi , a. khosla , m. bernstein , et al . , imagenet larg scale visual recognit challeng , intern journal comput vision , vol . 115 , . 3 , pp . 211252 , 2015 . 53 j. redmon a. farhadi , yolo9000 better , faster , stronger , proceed ieee confer comput vision pattern recognit , pp . 72637271 , 2017 . 54 j. redmon a. farhadi , yolov3 increment improv , arxiv preprint arxiv1804.02767 , 2018 . 32publish journal paper machin learn knowledg extract 55 i. krasin , t. duerig , n. alldrin , v . ferrari , s. abuelhaija , a. kuznetsova , h. rom , j. uijl , s. popov , a. veit , et al . , openimag public dataset largescal multilabel multiclass imag classif , dataset avail httpsgithub . comopenimag , vol . 2 , . 3 , p. 18 , 2017 . 56 k. , x. zhang , s. ren , j. sun , spatial pyramid pool deep convolut network visual recognit , ieee transact pattern analysi machin intellig , vol . 37 , . 9 , pp . 19041916 , 2015 . 57 t.i . lin , p. dollr , r. girshick , k. , b. hariharan , s. belongi , featur pyramid network object detect , proceed ieee confer comput vision pattern recognit , pp . 21172125 , 2017 . 58 a. bochkovskiy , c.i . wang , h.i . m. liao , yolov4 optim speed accuraci object detect , arxiv preprint arxiv2004.10934 , 2020 . 59 l.c . chen , g. papandr , i. kokkino , k. murphi , a. l. yuill , deeplab semant imag segment deep convolut net , atrou convolut , fulli connect crf , ieee transact pattern analysi machin intellig , vol . 40 , . 4 , pp . 834848 , 2017 . 60 s. liu , d. huang , et al . , recept field block net accur fast object detect , proceed european confer comput vision eccv , pp . 385400 , 2018 . 61 k. , x. zhang , s. ren , j. sun , deep residu learn imag recognit , proceed ieee confer comput vision pattern recognit , pp . 770778 , 2016 . 62 b. hariharan , p. arbelez , r. girshick , j. malik , hypercolumn object segment finegrain local , proceed ieee confer comput vision pattern recognit , pp . 447456 , 2015 . 63 q. zhao , t. sheng , . wang , z. tang , . chen , l. cai , h. ling , m2det singleshot object detector base multilevel featur pyramid network , proceed aaai confer artifici intellig , vol . 33 , pp . 92599266 , 2019 . 64 k. , x. zhang , s. ren , j. sun , delv deep rectifi surpass humanlevel perform imagenet classif , proceed ieee intern confer comput vision , pp . 10261034 , 2015 . 65 d. misra , mish self regular nonmonoton neural activ function , arxiv preprint arxiv1908.08681 , vol . 4 , . 2 , pp . 1048550 , 2019 . 66 n. bodla , b. singh , r. chellappa , l. s. davi , softnmsimprov object detect one line code , inproceed ieee intern confer comput vision , pp . 55615569 , 2017 . 67 s. xie , r. girshick , p. dollr , z. tu , k. , aggreg residu transform deep neural network , inproceed ieee confer comput vision pattern recognit , pp . 14921500 , 2017 . 68 m. tan q. le , efficientnet rethink model scale convolut neural network , intern confer machin learn , pp . 61056114 , pmlr , 2019 . 69 c.i . wang , h.i . m. liao , .h . wu , p.i . chen , j.w . hsieh , i.h . yeh , cspnet new backbon enhanc learn capabl cnn , proceed ieeecvf confer comput vision pattern recognit workshop , pp . 390391 , 2020 . 70 s. liu , l. qi , h. qin , j. shi , j. jia , path aggreg network instanc segment , proceed ieee confer comput vision pattern recognit , pp . 87598768 , 2018 . 71 s. woo , j. park , j.i . lee , i. s. kweon , cbam convolut block attent modul , proceed european confer comput vision eccv , pp . 319 , 2018 . 72 g. ghiasi , t.i . lin , q. v . le , dropblock regular method convolut network , advanc neural inform process system , vol . 31 , 2018 . 73 n. srivastava , g. hinton , a. krizhevski , i. sutskev , r. salakhutdinov , dropout simpl way prevent neural network overfit , journal machin learn research , vol . 15 , . 1 , pp . 19291958 , 2014 . 74 c. szegedi , v . vanhouck , s. ioff , j. shlen , z. wojna , rethink incept architectur comput vision , proceed ieee confer comput vision pattern recognit , pp . 28182826 , 2016 . 75 m. a. islam , s. naha , m. rochan , n. bruce , . wang , label refin network coarsetofin semant segment , arxiv preprint arxiv1703.00551 , 2017 . 33publish journal paper machin learn knowledg extract 76 z. zheng , p. wang , w. liu , j. li , r. ye , d. ren , distancei loss faster better learn bound box regress , proceed aaai confer artifici intellig , vol . 34 , pp . 1299313000 , 2020 . 77 s. ioff c. szegedi , batch normal acceler deep network train reduc intern covari shift , intern confer machin learn , pp . 448456 , pmlr , 2015 . 78 i. loshchilov f. hutter , sgdr stochast gradient descent warm restart , arxiv preprint arxiv1608.03983 , 2016 . 79 s. wang , j. zhao , n. ta , x. zhao , m. xiao , h. wei , realtim deep learn forest fire monitor algorithm base improv prune kd model , journal realtim imag process , vol . 18 , . 6 , pp . 23192329 , 2021 . 80 g. jocher , yolov5 ultralyt . httpsgithub.comultralyticsyolov5 , 2020. access febru ari 30 , 2023 . 81 d. hendryck k. gimpel , gaussian error linear unit gelu , arxiv preprint arxiv1606.08415 , 2016 . 82 g. ghiasi , . cui , a. sriniva , r. qian , t.i . lin , e. d. cubuk , q. v . le , b. zoph , simpl copypast strong data augment method instanc segment , proceed ieeecvf confer comput vision pattern recognit , pp . 29182928 , 2021 . 83 h. zhang , m. cis , . n. dauphin , d. lopezpaz , mixup beyond empir risk minim , arxiv preprint arxiv1710.09412 , 2017 . 84 a. buslaev , v . i. iglovikov , e. khvedchenya , a. parinov , m. druzhinin , a. a. kalinin , albument fast flexibl imag augment , inform , vol . 11 , . 2 , 2020 . 85 m. contributor , yolov5 mmyolo . httpsgithub.comopenmmlabmmyolotreemain configsyolov5 , 2023. access may 13 , 2023 . 86 ultralyt , model structur . httpsdocs.ultralytics.comyolov5tutorialsarchitectur description1modelstructur , 2023. access may 14 , 2023 . 87 c.i . wang , a. bochkovskiy , h.i . m. liao , scaledyolov4 scale cross stage partial network , proceed ieeecvf confer comput vision pattern recognit , pp . 1302913038 , 2021 . 88 x. long , k. deng , g. wang , . zhang , q. dang , . gao , h. shen , j. ren , s. han , e. ding , et al . , ppyolo effect effici implement object detector , arxiv preprint arxiv2007.12099 , 2020 . 89 c.i . wang , i.h . yeh , h.i . m. liao , learn one represent unifi network multipl task , arxiv preprint arxiv2105.04206 , 2021 . 90 z. ge , s. liu , f. wang , z. li , j. sun , yolox exceed yolo seri 2021 , arxiv preprint arxiv2107.08430 , 2021 . 91 h. law j. deng , cornernet detect object pair keypoint , proceed european confer comput vision eccv , pp . 734750 , 2018 . 92 k. duan , s. bai , l. xie , h. qi , q. huang , q. tian , centernet keypoint triplet object detect , proceed ieeecvf intern confer comput vision , pp . 65696578 , 2019 . 93 z. tian , c. shen , h. chen , t. , fco fulli convolut onestag object detect , proceed ieeecvf intern confer comput vision , pp . 96279636 , 2019 . 94 g. song , . liu , x. wang , revisit sibl head object detector , proceed ieeecvf confer comput vision pattern recognit , pp . 1156311572 , 2020 . 95 . wu , . chen , l. yuan , z. liu , l. wang , h. li , . fu , rethink classif local object detect , proceed ieeecvf confer comput vision pattern recognit , pp . 1018610195 , 2020 . 96 z. ge , s. liu , z. li , o. yoshi , j. sun , ota optim transport assign object detect , proceed ieeecvf confer comput vision pattern recognit , pp . 303312 , 2021 . 97 c. li , l. li , h. jiang , k. weng , . geng , l. li , z. ke , q. li , m. cheng , w. nie , et al . , yolov6 singlestag object detect framework industri applic , arxiv preprint arxiv2209.02976 , 2022 . 98 x. ding , x. zhang , n. , j. han , g. ding , j. sun , repvgg make vggstyle convnet great , proceed ieeecvf confer comput vision pattern recognit , pp . 1373313742 , 2021 . 99 m. contributor , yolov6 mmyolo . httpsgithub.comopenmmlabmmyolotreemain configsyolov6 , 2023. access may 13 , 2023 . 34publish journal paper machin learn knowledg extract 100 c. feng , . zhong , . gao , m. r. scott , w. huang , tood taskalign onestag object detect , 2021 ieeecvf intern confer comput vision iccv , pp . 34903499 , ieee comput societi , 2021 . 101 h. zhang , . wang , f. dayoub , n. sunderhauf , varifocalnet iouawar den object detector , proceed ieeecvf confer comput vision pattern recognit , pp . 85148523 , 2021 . 102 z. gevorgyan , siou loss power learn bound box regress , arxiv preprint arxiv2205.12740 , 2022 . 103 h. rezatofighi , n. tsoi , j. gwak , a. sadeghian , i. reid , s. savares , gener intersect union metric loss bound box regress , proceed ieeecvf confer comput vision pattern recognit , pp . 658666 , 2019 . 104 x. ding , h. chen , x. zhang , k. huang , j. han , g. ding , reparameter optim rather architectur , arxiv preprint arxiv2205.15242 , 2022 . 105 c. shu , . liu , j. gao , z. yan , c. shen , channelwis knowledg distil den predict , proceed ieeecvf intern confer comput vision , pp . 53115320 , 2021 . 106 c.i . wang , a. bochkovskiy , h.i . m. liao , yolov7 trainabl bagoffreebi set new stateoftheart realtim object detector , arxiv preprint arxiv2207.02696 , 2022 . 107 m. contributor , yolov7 mmyolo . httpsgithub.comopenmmlabmmyolotreemain configsyolov7 , 2023. access may 13 , 2023 . 108 c.i . wang , h.i . m. liao , i.h . yeh , design network design strategi gradient path analysi , arxiv preprint arxiv2211.04800 , 2022 . 109 g. huang , z. liu , l. van der maaten , k. q. weinberg , den connect convolut network , proceed ieee confer comput vision pattern recognit , pp . 47004708 , 2017 . 110 x. xu , . jiang , w. chen , . huang , . zhang , x. sun , damoyolo report realtim object detect design , arxiv preprint arxiv2211.15444 , 2022 . 111 alibaba , tinyna . httpsgithub.comalibabalightweightneuralarchitecturesearch , 2023. access march 18 , 2023 . 112 z. tan , j. wang , x. sun , m. lin , h. li , et al . , giraffedet heavyneck paradigm object detect , intern confer learn represent , 2021 . 113 g. jocher , a. chaurasia , j. qiu , yolo ultralyt . httpsgithub.comultralyt ultralyt , 2023. access februari 30 , 2023 . 114 x. li , w. wang , l. wu , s. chen , x. hu , j. li , j. tang , j. yang , gener focal loss learn qualifi distribut bound box den object detect , advanc neural inform process system , vol . 33 , pp . 2100221012 , 2020 . 115 m. contributor , yolov8 mmyolo . httpsgithub.comopenmmlabmmyolotreemain configsyolov8 , 2023. access may 13 , 2023 . 116 . , d. yu , t. wu , h. wang , paddlepaddl opensourc deep learn platform industri practic , frontier data domput , vol . 1 , . 1 , pp . 105115 , 2019 . 117 j. dai , h. qi , . xiong , . li , g. zhang , h. hu , . wei , deform convolut network , proceed ieee intern confer comput vision , pp . 764773 , 2017 . 118 w. xinlong , z. rufeng , k. tao , l. lei , s. chunhua , solov2 dynam , faster stronger , proc . nip , 2020 . 119 r. liu , j. lehman , p. molino , f. petroski , e. frank , a. sergeev , j. yosinski , intrigu fail convolut neural network coordconv solut , advanc neural inform process system , vol . 31 , 2018 . 120 x. huang , x. wang , w. lv , x. bai , x. long , k. deng , q. dang , s. han , q. liu , x. hu , et al . , ppyolov2 practic object detector , arxiv preprint arxiv2104.10419 , 2021 . 121 s. xu , x. wang , w. lv , q. chang , c. cui , k. deng , g. wang , q. dang , s. wei , . du , et al . , ppyolo evolv version yolo , arxiv preprint arxiv2203.16250 , 2022 . 122 l. rao , treenet lightweight oneshot aggreg convolut network , arxiv preprint arxiv2109.12342 , 2021 . 35publish journal paper machin learn knowledg extract 123 m. contributor , ppyolo mmyolo . httpsgithub.comopenmmlabmmyolotreemain configsppyolo , 2023. access may 13 , 2023 . 124 r. team , yolona deci achiev stateoftheart perform object detect use neural ar chitectur search . httpsdeci.aiblogyolonasobjectdetectionfoundationmodel , 2023. access may 12 , 2023 . 125 x. chu , l. li , b. zhang , make repvgg greater quantizationawar approach , arxiv preprint arxiv2212.01593 , 2022 . 126 s. shao , z. li , t. zhang , c. peng , g. yu , x. zhang , j. li , j. sun , objects365 largescal , highqual dataset object detect , proceed ieeecvf intern confer comput vision , pp . 84308439 , 2019 . 127 a. vaswani , n. shazeer , n. parmar , j. uszkoreit , l. jone , a. n. gomez , . kaiser , i. polosukhin , attent need , advanc neural inform process system , vol . 30 , 2017 . 128 . fang , b. liao , x. wang , j. fang , j. qi , r. wu , j. niu , w. liu , look one sequenc rethink transform vision object detect , advanc neural inform process system , vol . 34 , pp . 2618326197 , 2021 . 129 a. dosovitskiy , l. beyer , a. kolesnikov , d. weissenborn , x. zhai , t. unterthin , m. dehghani , m. minder , g. heigold , s. gelli , et al . , imag worth 16x16 word transform imag recognit scale , arxiv preprint arxiv2010.11929 , 2020 . 130 n. carion , f. massa , g. synnaev , n. usuni , a. kirillov , s. zagoruyko , endtoend object detect transform , european confer comput vision , pp . 213229 , springer , 2020 . 131 z. zhang , x. lu , g. cao , . yang , l. jiao , f. liu , vityolo transformerbas yolo object detect , inproceed ieeecvf intern confer comput vision , pp . 27992808 , 2021 . 132 z. guo , c. wang , g. yang , z. huang , g. li , msftyolo improv yolov5 base transform detect defect steel surfac , sensor , vol . 22 , . 9 , p. 3467 , 2022 . 133 . liu , g. , z. wang , w. li , h. huang , nrtyolo improv yolov5 base nest residu transform tini remot sen object detect , sensor , vol . 22 , . 13 , p. 4953 , 2022 . 134 g. . xia , x. bai , j. ding , z. zhu , s. belongi , j. luo , m. datcu , m. pelillo , l. zhang , dota largescal dataset object detect aerial imag , proceed ieee confer comput vision pattern recognit , pp . 39743983 , 2018 . 135 s. wang , s. gao , l. zhou , r. liu , h. zhang , j. liu , . jia , j. qian , yolosd small ship detect sar imag multiscal convolut featur transform modul , remot sen , vol . 14 , . 20 , p. 5268 , 2022 . 136 s. wei , x. zeng , q. qu , m. wang , h. su , j. shi , hrsid highresolut sar imag dataset ship detect instanc segment , ieee access , vol . 8 , pp . 120234120254 , 2020 . 137 h. ouyang , deyo detr yolo stepbystep object detect , arxiv preprint arxiv2211.06588 , 2022 . 138 ultralyt , yolov8ultralyt yolov8 document . httpsdocs.ultralytics.commodel yolov8 , 2023. access januari 7 , 2024 . 36\n",
      "\n",
      "Extracted Sections:\n",
      "Abstract:\n",
      "YOLO has become a central real-time object detection system for robotics, driverless cars, and video\n",
      "monitoring applications. We present a comprehensive analysis of YOLO’s evolution, examining the\n",
      "innovations and contributions in each iteration from the original YOLO up to YOLOv8, YOLO-NAS,\n",
      "and YOLO with Transformers. We start by describing the standard metrics and postprocessing; then,\n",
      "we discuss the major changes in network architecture and training tricks for each model. Finally, we\n",
      "summarize the essential lessons from YOLO’s development and provide a perspective on its future,\n",
      "highlighting potential research directions to enhance real-time object detection systems.\n",
      "Keywords YOLO ·Object detection ·Deep Learning ·Computer Vision\n",
      "\n",
      "Introduction:\n",
      "Real-time object detection has emerged as a critical component in numerous applications, spanning various fields such\n",
      "as autonomous vehicles, robotics, video surveillance, and augmented reality. Among the different object detection\n",
      "algorithms, the YOLO (You Only Look Once) framework has stood out for its remarkable balance of speed and accuracy,\n",
      "enabling the rapid and reliable identification of objects in images. Since its inception, the YOLO family has evolved\n",
      "through multiple iterations, each building upon the previous versions to address limitations and enhance performance\n",
      "(see Figure 1). This paper aims to provide a comprehensive review of the YOLO framework’s development, from the\n",
      "original YOLOv1 to the latest YOLOv8, elucidating the key innovations, differences, and improvements across each\n",
      "version.\n",
      "In addition to the YOLO framework, the field of object detection and image processing has developed several other\n",
      "notable\n",
      "\n",
      "References:\n",
      "[1]R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hierarchies for accurate object detection and\n",
      "semantic segmentation,” in Proceedings of the IEEE conference on computer vision and pattern recognition ,\n",
      "pp. 580–587, 2014.\n",
      "[2]R. Girshick, “Fast r-cnn,” in Proceedings of the IEEE international conference on computer vision , pp. 1440–1448,\n",
      "2015.\n",
      "[3]S. Ren, K. He, R. Girshick, and J. Sun, “Faster r-cnn: Towards real-time object detection with region proposal\n",
      "networks,” Advances in neural information processing systems , vol. 28, 2015.\n",
      "[4]W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y . Fu, and A. C. Berg, “Ssd: Single shot multibox\n",
      "detector,” in Computer Vision–ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October\n",
      "11–14, 2016, Proceedings, Part I 14 , pp. 21–37, Springer, 2016.\n",
      "[5]K. He, G. Gkioxari, P. Dollár, and R. Girshick, “Mask r-cnn,” in Proceedings of the IEEE international conference\n",
      "on computer vision , pp. 2961–2969, 2017.\n",
      "[6]T.-Y . Lin, P. Goyal, R. Girshick, K. He, and P. Dollár, “Focal loss for dense object detection,” in Proceedings of\n",
      "the IEEE international conference on computer vision , pp. 2980–2988, 2017.\n",
      "[7]M. Tan, R. Pang, and Q. V . Le, “Efficientdet: Scalable and efficient object detection,” in Proceedings of the\n",
      "IEEE/CVF conference on computer vision and pattern recognition , pp. 10781–10790, 2020.\n",
      "[8]B. Bhavya Sree, V . Yashwanth Bharadwaj, and N. Neelima, “An inter-comparative survey on state-of-the-art\n",
      "detectors—r-cnn, yolo, and ssd,” in Intelligent Manufacturing and Energy Sustainability: Proceedings of ICIMES\n",
      "2020 , pp. 475–483, Springer, 2021.\n",
      "[9]T. Diwan, G. Anirudh, and J. V . Tembhurne, “Object detection using yolo: Challenges, architectural successors,\n",
      "datasets and applications,” multimedia Tools and Applications , vol. 82, no. 6, pp. 9243–9275, 2023.\n",
      "[10] M. Hussain, “Yolo-v1 to yolo-v8, the rise of yolo and its complementary nature toward digital manufacturing\n",
      "and industrial defect detection,” Machines , vol. 11, no. 7, p. 677, 2023.\n",
      "[11] W. Lan, J. Dang, Y . Wang, and S. Wang, “Pedestrian detection based on yolo network model,” in 2018 IEEE\n",
      "international conference on mechatronics and automation (ICMA) , pp. 1547–1551, IEEE, 2018.\n",
      "30Published as a Journal paper at Machine Learning and Knowledge Extraction\n",
      "[12] W.-Y . Hsu and W.-Y . Lin, “Adaptive fusion of multi-scale yolo for pedestrian detection,” IEEE Access , vol. 9,\n",
      "pp. 110063–110073, 2021.\n",
      "[13] A. Benjumea, I. Teeti, F. Cuzzolin, and A. Bradley, “Yolo-z: Improving small object detection in yolov5 for\n",
      "autonomous vehicles,” arXiv preprint arXiv:2112.11798 , 2021.\n",
      "[14] N. M. A. A. Dazlee, S. A. Khalil, S. Abdul-Rahman, and S. Mutalib, “Object detection for autonomous vehicles\n",
      "with sensor-based technology using yolo,” International Journal of Intelligent Systems and Applications in\n",
      "Engineering , vol. 10, no. 1, pp. 129–134, 2022.\n",
      "[15] S. Liang, H. Wu, L. Zhen, Q. Hua, S. Garg, G. Kaddoum, M. M. Hassan, and K. Yu, “Edge yolo: Real-time\n",
      "intelligent object detection system based on edge-cloud cooperation in autonomous vehicles,” IEEE Transactions\n",
      "on Intelligent Transportation Systems , vol. 23, no. 12, pp. 25345–25360, 2022.\n",
      "[16] Q. Li, X. Ding, X. Wang, L. Chen, J. Son, and J.-Y . Song, “Detection and identification of moving objects at\n",
      "busy traffic road based on yolo v4,” The Journal of the Institute of Internet, Broadcasting and Communication ,\n",
      "vol. 21, no. 1, pp. 141–148, 2021.\n",
      "[17] S. Shinde, A. Kothari, and V . Gupta, “Yolo based human action recognition and localization,” Procedia computer\n",
      "science , vol. 133, pp. 831–838, 2018.\n",
      "[18] A. H. Ashraf, M. Imran, A. M. Qahtani, A. Alsufyani, O. Almutiry, A. Mahmood, M. Attique, and M. Habib,\n",
      "“Weapons detection for security and video surveillance using cnn and yolo-v5s,” CMC-Comput. Mater. Contin ,\n",
      "vol. 70, pp. 2761–2775, 2022.\n",
      "[19] Y . Zheng and H. Zhang, “Video analysis in sports by lightweight object detection network under the background\n",
      "of sports industry development,” Computational Intelligence and Neuroscience , vol. 2022, 2022.\n",
      "[20] H. Ma, T. Celik, and H. Li, “Fer-yolo: Detection and classification based on facial expressions,” in Image and\n",
      "Graphics: 11th International Conference, ICIG 2021, Haikou, China, August 6–8, 2021, Proceedings, Part I 11 ,\n",
      "pp. 28–39, Springer, 2021.\n",
      "[21] Y . Tian, G. Yang, Z. Wang, H. Wang, E. Li, and Z. Liang, “Apple detection during different growth stages in\n",
      "orchards using the improved yolo-v3 model,” Computers and electronics in agriculture , vol. 157, pp. 417–426,\n",
      "2019.\n",
      "[22] D. Wu, S. Lv, M. Jiang, and H. Song, “Using channel pruning-based yolo v4 deep learning algorithm for\n",
      "the real-time and accurate detection of apple flowers in natural environments,” Computers and Electronics in\n",
      "Agriculture , vol. 178, p. 105742, 2020.\n",
      "[23] M. Lippi, N. Bonucci, R. F. Carpio, M. Contarini, S. Speranza, and A. Gasparri, “A yolo-based pest detection\n",
      "system for precision agriculture,” in 2021 29th Mediterranean Conference on Control and Automation (MED) ,\n",
      "pp. 342–347, IEEE, 2021.\n",
      "[24] W. Yang and Z. Jiachun, “Real-time face detection based on yolo,” in 2018 1st IEEE international conference on\n",
      "knowledge innovation and invention (ICKII) , pp. 221–224, IEEE, 2018.\n",
      "[25] W. Chen, H. Huang, S. Peng, C. Zhou, and C. Zhang, “Yolo-face: a real-time face detector,” The Visual Computer ,\n",
      "vol. 37, pp. 805–813, 2021.\n",
      "[26] M. A. Al-Masni, M. A. Al-Antari, J.-M. Park, G. Gi, T.-Y . Kim, P. Rivera, E. Valarezo, M.-T. Choi, S.-M. Han,\n",
      "and T.-S. Kim, “Simultaneous detection and classification of breast masses in digital mammograms via a deep\n",
      "learning yolo-based cad system,” Computer methods and programs in biomedicine , vol. 157, pp. 85–94, 2018.\n",
      "[27] Y . Nie, P. Sommella, M. O’Nils, C. Liguori, and J. Lundgren, “Automatic detection of melanoma with yolo deep\n",
      "convolutional neural networks,” in 2019 E-Health and Bioengineering Conference (EHB) , pp. 1–4, IEEE, 2019.\n",
      "[28] H. M. Ünver and E. Ayan, “Skin lesion segmentation in dermoscopic images with combination of yolo and\n",
      "grabcut algorithm,” Diagnostics , vol. 9, no. 3, p. 72, 2019.\n",
      "[29] L. Tan, T. Huangfu, L. Wu, and W. Chen, “Comparison of retinanet, ssd, and yolo v3 for real-time pill\n",
      "identification,” BMC medical informatics and decision making , vol. 21, pp. 1–11, 2021.\n",
      "[30] L. Cheng, J. Li, P. Duan, and M. Wang, “A small attentional yolo model for landslide detection from satellite\n",
      "remote sensing images,” Landslides , vol. 18, no. 8, pp. 2751–2765, 2021.\n",
      "[31] M.-T. Pham, L. Courtrai, C. Friguet, S. Lefèvre, and A. Baussard, “Yolo-fine: One-stage detector of small objects\n",
      "under various backgrounds in remote sensing images,” Remote Sensing , vol. 12, no. 15, p. 2501, 2020.\n",
      "[32] Y . Qing, W. Liu, L. Feng, and W. Gao, “Improved yolo network for free-angle remote sensing target detection,”\n",
      "Remote Sensing , vol. 13, no. 11, p. 2171, 2021.\n",
      "31Published as a Journal paper at Machine Learning and Knowledge Extraction\n",
      "[33] Z. Zakria, J. Deng, R. Kumar, M. S. Khokhar, J. Cai, and J. Kumar, “Multiscale and direction target detecting in\n",
      "remote sensing images via modified yolo-v4,” IEEE Journal of Selected Topics in Applied Earth Observations\n",
      "and Remote Sensing , vol. 15, pp. 1039–1048, 2022.\n",
      "[34] P. Kumar, S. Narasimha Swamy, P. Kumar, G. Purohit, and K. S. Raju, “Real-time, yolo-based intelligent\n",
      "surveillance and monitoring system using jetson tx2,” in Data Analytics and Management: Proceedings of\n",
      "ICDAM , pp. 461–471, Springer, 2021.\n",
      "[35] K. Bhambani, T. Jain, and K. A. Sultanpure, “Real-time face mask and social distancing violation detection\n",
      "system using yolo,” in 2020 IEEE Bangalore humanitarian technology conference (B-HTC) , pp. 1–6, IEEE,\n",
      "2020.\n",
      "[36] J. Li, Z. Su, J. Geng, and Y . Yin, “Real-time detection of steel strip surface defects based on improved yolo\n",
      "detection network,” IFAC-PapersOnLine , vol. 51, no. 21, pp. 76–81, 2018.\n",
      "[37] E. N. Ukhwah, E. M. Yuniarno, and Y . K. Suprapto, “Asphalt pavement pothole detection using deep learning\n",
      "method based on yolo neural network,” in 2019 International Seminar on Intelligent Technology and Its\n",
      "Applications (ISITIA) , pp. 35–40, IEEE, 2019.\n",
      "[38] Y . Du, N. Pan, Z. Xu, F. Deng, Y . Shen, and H. Kang, “Pavement distress detection and classification based on\n",
      "yolo network,” International Journal of Pavement Engineering , vol. 22, no. 13, pp. 1659–1672, 2021.\n",
      "[39] R.-C. Chen et al. , “Automatic license plate recognition via sliding-window darknet-yolo deep learning,” Image\n",
      "and Vision Computing , vol. 87, pp. 47–56, 2019.\n",
      "[40] C. Dewi, R.-C. Chen, X. Jiang, and H. Yu, “Deep convolutional neural network for enhancing traffic sign\n",
      "recognition developed on yolo v4,” Multimedia Tools and Applications , vol. 81, no. 26, pp. 37821–37845, 2022.\n",
      "[41] A. M. Roy, J. Bhaduri, T. Kumar, and K. Raj, “Wildect-yolo: An efficient and robust computer vision-based\n",
      "accurate object localization model for automated endangered wildlife detection,” Ecological Informatics , vol. 75,\n",
      "p. 101919, 2023.\n",
      "[42] S. Kulik and A. Shtanko, “Experiments with neural net object detection system yolo on small training datasets\n",
      "for intelligent robotics,” in Advanced Technologies in Robotics and Intelligent Systems: Proceedings of ITR 2019 ,\n",
      "pp. 157–162, Springer, 2020.\n",
      "[43] D. H. Dos Reis, D. Welfer, M. A. De Souza Leite Cuadros, and D. F. T. Gamarra, “Mobile robot navigation using\n",
      "an object recognition software with rgbd images and the yolo algorithm,” Applied Artificial Intelligence , vol. 33,\n",
      "no. 14, pp. 1290–1305, 2019.\n",
      "[44] O. Sahin and S. Ozer, “Yolodrone: Improved yolo architecture for object detection in drone images,” in 2021\n",
      "44th International Conference on Telecommunications and Signal Processing (TSP) , pp. 361–365, IEEE, 2021.\n",
      "[45] C. Chen, Z. Zheng, T. Xu, S. Guo, S. Feng, W. Yao, and Y . Lan, “Yolo-based uav technology: A review of the\n",
      "research and its applications,” Drones , vol. 7, no. 3, p. 190, 2023.\n",
      "[46] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman, “The pascal visual object classes (voc)\n",
      "challenge,” International journal of computer vision , vol. 88, no. 2, pp. 303–338, 2010.\n",
      "[47] T.-Y . Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick, “Microsoft coco:\n",
      "Common objects in context,” in European conference on computer vision , pp. 740–755, Springer, 2014.\n",
      "[48] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look once: Unified, real-time object detection,” in\n",
      "Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 779–788, 2016.\n",
      "[49] A. L. Maas, A. Y . Hannun, A. Y . Ng, et al. , “Rectifier nonlinearities improve neural network acoustic models,” in\n",
      "Proc. icml , vol. 30, p. 3, Atlanta, Georgia, USA, 2013.\n",
      "[50] C. Szegedy, W. Liu, Y . Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V . Vanhoucke, and A. Rabinovich,\n",
      "“Going deeper with convolutions,” in Proceedings of the IEEE conference on computer vision and pattern\n",
      "recognition , pp. 1–9, 2015.\n",
      "[51] M. Lin, Q. Chen, and S. Yan, “Network in network,” arXiv preprint arXiv:1312.4400 , 2013.\n",
      "[52] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein,\n",
      "et al. , “Imagenet large scale visual recognition challenge,” International journal of computer vision , vol. 115,\n",
      "no. 3, pp. 211–252, 2015.\n",
      "[53] J. Redmon and A. Farhadi, “Yolo9000: better, faster, stronger,” in Proceedings of the IEEE conference on\n",
      "computer vision and pattern recognition , pp. 7263–7271, 2017.\n",
      "[54] J. Redmon and A. Farhadi, “Yolov3: An incremental improvement,” arXiv preprint arXiv:1804.02767 , 2018.\n",
      "32Published as a Journal paper at Machine Learning and Knowledge Extraction\n",
      "[55] I. Krasin, T. Duerig, N. Alldrin, V . Ferrari, S. Abu-El-Haija, A. Kuznetsova, H. Rom, J. Uijlings, S. Popov,\n",
      "A. Veit, et al. , “Openimages: A public dataset for large-scale multi-label and multi-class image classification,”\n",
      "Dataset available from https://github. com/openimages , vol. 2, no. 3, p. 18, 2017.\n",
      "[56] K. He, X. Zhang, S. Ren, and J. Sun, “Spatial pyramid pooling in deep convolutional networks for visual\n",
      "recognition,” IEEE transactions on pattern analysis and machine intelligence , vol. 37, no. 9, pp. 1904–1916,\n",
      "2015.\n",
      "[57] T.-Y . Lin, P. Dollár, R. Girshick, K. He, B. Hariharan, and S. Belongie, “Feature pyramid networks for object\n",
      "detection,” in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2117–2125,\n",
      "2017.\n",
      "[58] A. Bochkovskiy, C.-Y . Wang, and H.-Y . M. Liao, “Yolov4: Optimal speed and accuracy of object detection,”\n",
      "arXiv preprint arXiv:2004.10934 , 2020.\n",
      "[59] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, “Deeplab: Semantic image segmentation\n",
      "with deep convolutional nets, atrous convolution, and fully connected crfs,” IEEE transactions on pattern analysis\n",
      "and machine intelligence , vol. 40, no. 4, pp. 834–848, 2017.\n",
      "[60] S. Liu, D. Huang, et al. , “Receptive field block net for accurate and fast object detection,” in Proceedings of the\n",
      "European conference on computer vision (ECCV) , pp. 385–400, 2018.\n",
      "[61] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proceedings of the IEEE\n",
      "conference on computer vision and pattern recognition , pp. 770–778, 2016.\n",
      "[62] B. Hariharan, P. Arbeláez, R. Girshick, and J. Malik, “Hypercolumns for object segmentation and fine-grained\n",
      "localization,” in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 447–456,\n",
      "2015.\n",
      "[63] Q. Zhao, T. Sheng, Y . Wang, Z. Tang, Y . Chen, L. Cai, and H. Ling, “M2det: A single-shot object detector based\n",
      "on multi-level feature pyramid network,” in Proceedings of the AAAI conference on artificial intelligence , vol. 33,\n",
      "pp. 9259–9266, 2019.\n",
      "[64] K. He, X. Zhang, S. Ren, and J. Sun, “Delving deep into rectifiers: Surpassing human-level performance on\n",
      "imagenet classification,” in Proceedings of the IEEE international conference on computer vision , pp. 1026–1034,\n",
      "2015.\n",
      "[65] D. Misra, “Mish: A self regularized non-monotonic neural activation function,” arXiv preprint arXiv:1908.08681 ,\n",
      "vol. 4, no. 2, pp. 10–48550, 2019.\n",
      "[66] N. Bodla, B. Singh, R. Chellappa, and L. S. Davis, “Soft-nms–improving object detection with one line of code,”\n",
      "inProceedings of the IEEE international conference on computer vision , pp. 5561–5569, 2017.\n",
      "[67] S. Xie, R. Girshick, P. Dollár, Z. Tu, and K. He, “Aggregated residual transformations for deep neural networks,”\n",
      "inProceedings of the IEEE conference on computer vision and pattern recognition , pp. 1492–1500, 2017.\n",
      "[68] M. Tan and Q. Le, “Efficientnet: Rethinking model scaling for convolutional neural networks,” in International\n",
      "conference on machine learning , pp. 6105–6114, PMLR, 2019.\n",
      "[69] C.-Y . Wang, H.-Y . M. Liao, Y .-H. Wu, P.-Y . Chen, J.-W. Hsieh, and I.-H. Yeh, “Cspnet: A new backbone that can\n",
      "enhance learning capability of cnn,” in Proceedings of the IEEE/CVF conference on computer vision and pattern\n",
      "recognition workshops , pp. 390–391, 2020.\n",
      "[70] S. Liu, L. Qi, H. Qin, J. Shi, and J. Jia, “Path aggregation network for instance segmentation,” in Proceedings of\n",
      "the IEEE conference on computer vision and pattern recognition , pp. 8759–8768, 2018.\n",
      "[71] S. Woo, J. Park, J.-Y . Lee, and I. S. Kweon, “Cbam: Convolutional block attention module,” in Proceedings of\n",
      "the European conference on computer vision (ECCV) , pp. 3–19, 2018.\n",
      "[72] G. Ghiasi, T.-Y . Lin, and Q. V . Le, “Dropblock: A regularization method for convolutional networks,” Advances\n",
      "in neural information processing systems , vol. 31, 2018.\n",
      "[73] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, “Dropout: a simple way to prevent\n",
      "neural networks from overfitting,” The journal of machine learning research , vol. 15, no. 1, pp. 1929–1958,\n",
      "2014.\n",
      "[74] C. Szegedy, V . Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, “Rethinking the inception architecture for computer\n",
      "vision,” in Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 2818–2826,\n",
      "2016.\n",
      "[75] M. A. Islam, S. Naha, M. Rochan, N. Bruce, and Y . Wang, “Label refinement network for coarse-to-fine semantic\n",
      "segmentation,” arXiv preprint arXiv:1703.00551 , 2017.\n",
      "33Published as a Journal paper at Machine Learning and Knowledge Extraction\n",
      "[76] Z. Zheng, P. Wang, W. Liu, J. Li, R. Ye, and D. Ren, “Distance-iou loss: Faster and better learning for bounding\n",
      "box regression,” in Proceedings of the AAAI conference on artificial intelligence , vol. 34, pp. 12993–13000,\n",
      "2020.\n",
      "[77] S. Ioffe and C. Szegedy, “Batch normalization: Accelerating deep network training by reducing internal covariate\n",
      "shift,” in International conference on machine learning , pp. 448–456, PMLR, 2015.\n",
      "[78] I. Loshchilov and F. Hutter, “Sgdr: Stochastic gradient descent with warm restarts,” arXiv preprint\n",
      "arXiv:1608.03983 , 2016.\n",
      "[79] S. Wang, J. Zhao, N. Ta, X. Zhao, M. Xiao, and H. Wei, “A real-time deep learning forest fire monitoring\n",
      "algorithm based on an improved pruned+ kd model,” Journal of Real-Time Image Processing , vol. 18, no. 6,\n",
      "pp. 2319–2329, 2021.\n",
      "[80] G. Jocher, “YOLOv5 by Ultralytics.” https://github.com/ultralytics/yolov5 , 2020. Accessed: Febru-\n",
      "ary 30, 2023.\n",
      "[81] D. Hendrycks and K. Gimpel, “Gaussian error linear units (gelus),” arXiv preprint arXiv:1606.08415 , 2016.\n",
      "[82] G. Ghiasi, Y . Cui, A. Srinivas, R. Qian, T.-Y . Lin, E. D. Cubuk, Q. V . Le, and B. Zoph, “Simple copy-paste is a\n",
      "strong data augmentation method for instance segmentation,” in Proceedings of the IEEE/CVF conference on\n",
      "computer vision and pattern recognition , pp. 2918–2928, 2021.\n",
      "[83] H. Zhang, M. Cisse, Y . N. Dauphin, and D. Lopez-Paz, “mixup: Beyond empirical risk minimization,” arXiv\n",
      "preprint arXiv:1710.09412 , 2017.\n",
      "[84] A. Buslaev, V . I. Iglovikov, E. Khvedchenya, A. Parinov, M. Druzhinin, and A. A. Kalinin, “Albumentations:\n",
      "Fast and flexible image augmentations,” Information , vol. 11, no. 2, 2020.\n",
      "[85] M. Contributors, “YOLOv5 by MMYOLO.” https://github.com/open-mmlab/mmyolo/tree/main/\n",
      "configs/yolov5 , 2023. Accessed: May 13, 2023.\n",
      "[86] Ultralytics, “Model Structure.” https://docs.ultralytics.com/yolov5/tutorials/architecture_\n",
      "description/#1-model-structure , 2023. Accessed: May 14, 2023.\n",
      "[87] C.-Y . Wang, A. Bochkovskiy, and H.-Y . M. Liao, “Scaled-yolov4: Scaling cross stage partial network,” in\n",
      "Proceedings of the IEEE/cvf conference on computer vision and pattern recognition , pp. 13029–13038, 2021.\n",
      "[88] X. Long, K. Deng, G. Wang, Y . Zhang, Q. Dang, Y . Gao, H. Shen, J. Ren, S. Han, E. Ding, et al. , “Pp-yolo: An\n",
      "effective and efficient implementation of object detector,” arXiv preprint arXiv:2007.12099 , 2020.\n",
      "[89] C.-Y . Wang, I.-H. Yeh, and H.-Y . M. Liao, “You only learn one representation: Unified network for multiple\n",
      "tasks,” arXiv preprint arXiv:2105.04206 , 2021.\n",
      "[90] Z. Ge, S. Liu, F. Wang, Z. Li, and J. Sun, “Yolox: Exceeding yolo series in 2021,” arXiv preprint\n",
      "arXiv:2107.08430 , 2021.\n",
      "[91] H. Law and J. Deng, “Cornernet: Detecting objects as paired keypoints,” in Proceedings of the European\n",
      "conference on computer vision (ECCV) , pp. 734–750, 2018.\n",
      "[92] K. Duan, S. Bai, L. Xie, H. Qi, Q. Huang, and Q. Tian, “Centernet: Keypoint triplets for object detection,” in\n",
      "Proceedings of the IEEE/CVF international conference on computer vision , pp. 6569–6578, 2019.\n",
      "[93] Z. Tian, C. Shen, H. Chen, and T. He, “Fcos: Fully convolutional one-stage object detection,” in Proceedings of\n",
      "the IEEE/CVF international conference on computer vision , pp. 9627–9636, 2019.\n",
      "[94] G. Song, Y . Liu, and X. Wang, “Revisiting the sibling head in object detector,” in Proceedings of the IEEE/CVF\n",
      "Conference on Computer Vision and Pattern Recognition , pp. 11563–11572, 2020.\n",
      "[95] Y . Wu, Y . Chen, L. Yuan, Z. Liu, L. Wang, H. Li, and Y . Fu, “Rethinking classification and localization for\n",
      "object detection,” in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition ,\n",
      "pp. 10186–10195, 2020.\n",
      "[96] Z. Ge, S. Liu, Z. Li, O. Yoshie, and J. Sun, “Ota: Optimal transport assignment for object detection,” in\n",
      "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 303–312, 2021.\n",
      "[97] C. Li, L. Li, H. Jiang, K. Weng, Y . Geng, L. Li, Z. Ke, Q. Li, M. Cheng, W. Nie, et al. , “Yolov6: A single-stage\n",
      "object detection framework for industrial applications,” arXiv preprint arXiv:2209.02976 , 2022.\n",
      "[98] X. Ding, X. Zhang, N. Ma, J. Han, G. Ding, and J. Sun, “Repvgg: Making vgg-style convnets great again,” in\n",
      "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 13733–13742, 2021.\n",
      "[99] M. Contributors, “YOLOv6 by MMYOLO.” https://github.com/open-mmlab/mmyolo/tree/main/\n",
      "configs/yolov6 , 2023. Accessed: May 13, 2023.\n",
      "34Published as a Journal paper at Machine Learning and Knowledge Extraction\n",
      "[100] C. Feng, Y . Zhong, Y . Gao, M. R. Scott, and W. Huang, “Tood: Task-aligned one-stage object detection,” in\n",
      "2021 IEEE/CVF International Conference on Computer Vision (ICCV) , pp. 3490–3499, IEEE Computer Society,\n",
      "2021.\n",
      "[101] H. Zhang, Y . Wang, F. Dayoub, and N. Sunderhauf, “Varifocalnet: An iou-aware dense object detector,” in\n",
      "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 8514–8523, 2021.\n",
      "[102] Z. Gevorgyan, “Siou loss: More powerful learning for bounding box regression,” arXiv preprint\n",
      "arXiv:2205.12740 , 2022.\n",
      "[103] H. Rezatofighi, N. Tsoi, J. Gwak, A. Sadeghian, I. Reid, and S. Savarese, “Generalized intersection over union:\n",
      "A metric and a loss for bounding box regression,” in Proceedings of the IEEE/CVF conference on computer\n",
      "vision and pattern recognition , pp. 658–666, 2019.\n",
      "[104] X. Ding, H. Chen, X. Zhang, K. Huang, J. Han, and G. Ding, “Re-parameterizing your optimizers rather than\n",
      "architectures,” arXiv preprint arXiv:2205.15242 , 2022.\n",
      "[105] C. Shu, Y . Liu, J. Gao, Z. Yan, and C. Shen, “Channel-wise knowledge distillation for dense prediction,” in\n",
      "Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 5311–5320, 2021.\n",
      "[106] C.-Y . Wang, A. Bochkovskiy, and H.-Y . M. Liao, “Yolov7: Trainable bag-of-freebies sets new state-of-the-art for\n",
      "real-time object detectors,” arXiv preprint arXiv:2207.02696 , 2022.\n",
      "[107] M. Contributors, “YOLOv7 by MMYOLO.” https://github.com/open-mmlab/mmyolo/tree/main/\n",
      "configs/yolov7 , 2023. Accessed: May 13, 2023.\n",
      "[108] C.-Y . Wang, H.-Y . M. Liao, and I.-H. Yeh, “Designing network design strategies through gradient path analysis,”\n",
      "arXiv preprint arXiv:2211.04800 , 2022.\n",
      "[109] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely connected convolutional networks,” in\n",
      "Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 4700–4708, 2017.\n",
      "[110] X. Xu, Y . Jiang, W. Chen, Y . Huang, Y . Zhang, and X. Sun, “Damo-yolo: A report on real-time object detection\n",
      "design,” arXiv preprint arXiv:2211.15444 , 2022.\n",
      "[111] Alibaba, “TinyNAS.” https://github.com/alibaba/lightweight-neural-architecture-search ,\n",
      "2023. Accessed: March 18, 2023.\n",
      "[112] Z. Tan, J. Wang, X. Sun, M. Lin, H. Li, et al. , “Giraffedet: A heavy-neck paradigm for object detection,” in\n",
      "International Conference on Learning Representations , 2021.\n",
      "[113] G. Jocher, A. Chaurasia, and J. Qiu, “YOLO by Ultralytics.” https://github.com/ultralytics/\n",
      "ultralytics , 2023. Accessed: February 30, 2023.\n",
      "[114] X. Li, W. Wang, L. Wu, S. Chen, X. Hu, J. Li, J. Tang, and J. Yang, “Generalized focal loss: Learning qualified\n",
      "and distributed bounding boxes for dense object detection,” Advances in Neural Information Processing Systems ,\n",
      "vol. 33, pp. 21002–21012, 2020.\n",
      "[115] M. Contributors, “YOLOv8 by MMYOLO.” https://github.com/open-mmlab/mmyolo/tree/main/\n",
      "configs/yolov8 , 2023. Accessed: May 13, 2023.\n",
      "[116] Y . Ma, D. Yu, T. Wu, and H. Wang, “Paddlepaddle: An open-source deep learning platform from industrial\n",
      "practice,” Frontiers of Data and Domputing , vol. 1, no. 1, pp. 105–115, 2019.\n",
      "[117] J. Dai, H. Qi, Y . Xiong, Y . Li, G. Zhang, H. Hu, and Y . Wei, “Deformable convolutional networks,” in Proceedings\n",
      "of the IEEE international conference on computer vision , pp. 764–773, 2017.\n",
      "[118] W. Xinlong, Z. Rufeng, K. Tao, L. Lei, and S. Chunhua, “Solov2: Dynamic, faster and stronger,” in Proc. NIPS ,\n",
      "2020.\n",
      "[119] R. Liu, J. Lehman, P. Molino, F. Petroski Such, E. Frank, A. Sergeev, and J. Yosinski, “An intriguing failing of\n",
      "convolutional neural networks and the coordconv solution,” Advances in neural information processing systems ,\n",
      "vol. 31, 2018.\n",
      "[120] X. Huang, X. Wang, W. Lv, X. Bai, X. Long, K. Deng, Q. Dang, S. Han, Q. Liu, X. Hu, et al. , “Pp-yolov2: A\n",
      "practical object detector,” arXiv preprint arXiv:2104.10419 , 2021.\n",
      "[121] S. Xu, X. Wang, W. Lv, Q. Chang, C. Cui, K. Deng, G. Wang, Q. Dang, S. Wei, Y . Du, et al. , “Pp-yoloe: An\n",
      "evolved version of yolo,” arXiv preprint arXiv:2203.16250 , 2022.\n",
      "[122] L. Rao, “Treenet: A lightweight one-shot aggregation convolutional network,” arXiv preprint arXiv:2109.12342 ,\n",
      "2021.\n",
      "35Published as a Journal paper at Machine Learning and Knowledge Extraction\n",
      "[123] M. Contributors, “PP-YOLOE by MMYOLO.” https://github.com/open-mmlab/mmyolo/tree/main/\n",
      "configs/ppyoloe , 2023. Accessed: May 13, 2023.\n",
      "[124] R. team, “YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Ar-\n",
      "chitecture Search.” https://deci.ai/blog/yolo-nas-object-detection-foundation-model/ , 2023.\n",
      "Accessed: May 12, 2023.\n",
      "[125] X. Chu, L. Li, and B. Zhang, “Make repvgg greater again: A quantization-aware approach,” arXiv preprint\n",
      "arXiv:2212.01593 , 2022.\n",
      "[126] S. Shao, Z. Li, T. Zhang, C. Peng, G. Yu, X. Zhang, J. Li, and J. Sun, “Objects365: A large-scale, high-quality\n",
      "dataset for object detection,” in Proceedings of the IEEE/CVF international conference on computer vision ,\n",
      "pp. 8430–8439, 2019.\n",
      "[127] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention\n",
      "is all you need,” Advances in neural information processing systems , vol. 30, 2017.\n",
      "[128] Y . Fang, B. Liao, X. Wang, J. Fang, J. Qi, R. Wu, J. Niu, and W. Liu, “You only look at one sequence: Rethinking\n",
      "transformer in vision through object detection,” Advances in Neural Information Processing Systems , vol. 34,\n",
      "pp. 26183–26197, 2021.\n",
      "[129] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer,\n",
      "G. Heigold, S. Gelly, et al. , “An image is worth 16x16 words: Transformers for image recognition at scale,”\n",
      "arXiv preprint arXiv:2010.11929 , 2020.\n",
      "[130] N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and S. Zagoruyko, “End-to-end object detection with\n",
      "transformers,” in European conference on computer vision , pp. 213–229, Springer, 2020.\n",
      "[131] Z. Zhang, X. Lu, G. Cao, Y . Yang, L. Jiao, and F. Liu, “Vit-yolo: Transformer-based yolo for object detection,”\n",
      "inProceedings of the IEEE/CVF international conference on computer vision , pp. 2799–2808, 2021.\n",
      "[132] Z. Guo, C. Wang, G. Yang, Z. Huang, and G. Li, “Msft-yolo: Improved yolov5 based on transformer for detecting\n",
      "defects of steel surface,” Sensors , vol. 22, no. 9, p. 3467, 2022.\n",
      "[133] Y . Liu, G. He, Z. Wang, W. Li, and H. Huang, “Nrt-yolo: Improved yolov5 based on nested residual transformer\n",
      "for tiny remote sensing object detection,” Sensors , vol. 22, no. 13, p. 4953, 2022.\n",
      "[134] G.-S. Xia, X. Bai, J. Ding, Z. Zhu, S. Belongie, J. Luo, M. Datcu, M. Pelillo, and L. Zhang, “Dota: A large-scale\n",
      "dataset for object detection in aerial images,” in Proceedings of the IEEE conference on computer vision and\n",
      "pattern recognition , pp. 3974–3983, 2018.\n",
      "[135] S. Wang, S. Gao, L. Zhou, R. Liu, H. Zhang, J. Liu, Y . Jia, and J. Qian, “Yolo-sd: Small ship detection in sar\n",
      "images by multi-scale convolution and feature transformer module,” Remote Sensing , vol. 14, no. 20, p. 5268,\n",
      "2022.\n",
      "[136] S. Wei, X. Zeng, Q. Qu, M. Wang, H. Su, and J. Shi, “Hrsid: A high-resolution sar images dataset for ship\n",
      "detection and instance segmentation,” Ieee Access , vol. 8, pp. 120234–120254, 2020.\n",
      "[137] H. Ouyang, “Deyo: Detr with yolo for step-by-step object detection,” arXiv preprint arXiv:2211.06588 , 2022.\n",
      "[138] Ultralytics, “YOLOv8—Ultralytics YOLOv8 Documentation.” https://docs.ultralytics.com/models/\n",
      "yolov8/ , 2023. Accessed: January 7, 2024.\n",
      "36\n",
      "\n",
      "Figures and Tables: {'Figures': ['Figure 1', 'Figure 1', 'Figure 2', 'Figure 2', 'Figure 3', 'Figure 3', 'Figure 4', 'Figure 4', 'Figure 5', 'Figure 5', 'Figure 6', 'Figure 6', 'Figure 7', 'Figure 8', 'Figure 7', 'Figure 8', 'Figure 9', 'Figure 9', 'Figure 10', 'Figure 10', 'Figure 9', 'Figure 11', 'Figure 11', 'Figure 12', 'Figure 12', 'Figure 13', 'Figure 13', 'Figure 15', 'Figure 14', 'Figure 16', 'Figure 15', 'Figure 16', 'Figure 17', 'Figure 17', 'Figure 18', 'Figure 18', 'Figure 19', 'Figure 19', 'Figure 20', 'Figure 20', 'Figure 21', 'Figure 21'], 'Tables': ['Table 1', 'Table 1', 'Table 2', 'Table 2', 'Table 2', 'Table 3', 'Table 3', 'Table 4']}\n",
      "\n",
      "Top Keywords: [('detect', 157), ('object', 154), ('yolo', 130), ('model', 129), ('architectur', 91), ('comput', 81), ('learn', 76), ('network', 68), ('predict', 63), ('convolut', 59)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1. Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove special characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.,!?\\s]\", \"\", text)\n",
    "\n",
    "    # 3. Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # 4. Tokenization\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # 5. Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # 6. Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # 7. Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "\n",
    "    # Return cleaned and processed text\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "def extract_sections(text):\n",
    "    # Extract Abstract\n",
    "    abstract = re.search(r\"abstract(.*?)(introduction|1\\s)\", text, re.DOTALL | re.IGNORECASE)\n",
    "    abstract_text = abstract.group(1).strip() if abstract else \"\"\n",
    "\n",
    "    # Extract Introduction\n",
    "    introduction = re.search(r\"introduction(.*?)(\\n\\d+|methods|related work)\", text, re.DOTALL | re.IGNORECASE)\n",
    "    intro_text = introduction.group(1).strip() if introduction else \"\"\n",
    "\n",
    "    # Extract References\n",
    "    references = re.search(r\"references(.*)$\", text, re.DOTALL | re.IGNORECASE)\n",
    "    references_text = references.group(1).strip() if references else \"\"\n",
    "\n",
    "    return {\n",
    "        \"Abstract\": abstract_text,\n",
    "        \"Introduction\": intro_text,\n",
    "        \"References\": references_text\n",
    "    }\n",
    "\n",
    "def extract_figures_and_tables(text):\n",
    "    figures = re.findall(r\"figure \\d+\", text, re.IGNORECASE)\n",
    "    tables = re.findall(r\"table \\d+\", text, re.IGNORECASE)\n",
    "    return {\n",
    "        \"Figures\": figures,\n",
    "        \"Tables\": tables\n",
    "    }\n",
    "\n",
    "def extract_keywords(text):\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) > 3]\n",
    "    word_counts = Counter(filtered_words)\n",
    "    return word_counts.most_common(10)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your extracted PDF text\n",
    "    pdf_text = pdf_text\n",
    "\n",
    "    # Preprocessing\n",
    "    cleaned_text = preprocess_text(pdf_text)\n",
    "    print(\"Cleaned Text:\\n\", cleaned_text)\n",
    "\n",
    "    # Extract Sections\n",
    "    sections = extract_sections(pdf_text)\n",
    "    print(\"\\nExtracted Sections:\")\n",
    "    for section, content in sections.items():\n",
    "        print(f\"{section}:\\n{content}\\n\")\n",
    "\n",
    "    # Extract Figures and Tables\n",
    "    figures_tables = extract_figures_and_tables(pdf_text)\n",
    "    print(\"Figures and Tables:\", figures_tables)\n",
    "\n",
    "    # Extract Keywords\n",
    "    keywords = extract_keywords(cleaned_text)\n",
    "    print(\"\\nTop Keywords:\", keywords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "950d2719-b08b-4164-a31b-eb53e3d6873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text:\n",
      " c omprehensive review yolo rchitectures in computer vision yolo v1toyolo v8and yolo na published journal paper at machine learning and knowledge extraction juan r terven instituto politecnico nacional cicata qro diana cordova esparza universidad autónoma de querétaro facultad de informática abstract yolo become central real time object detection system for robotics driverless car and video monitoring application present comprehensive analysis yolo evolution examining innovation and contribution in iteration original yolo yolov8 yolo na and yolo transformer start by describing standard metric and postprocessing discus major change in network architecture and training trick for model finally summarize essential lesson yolo development and provide perspective on future highlighting potential research direction enhance real time object detection system keywords yolo detection learning vision 1 introduction real time object detection emerged critical component in numerous application spanning various field autonomous vehicle robotics video surveillance and augmented reality among different object detection algorithm yolo look framework stood for remarkable balance speed and accuracy enabling rapid and reliable identification object in image since inception yolo family evolved multiple iteration building upon previous version address limitation and enhance performance see figure 1 paper aim provide comprehensive review yolo framework development original yolov1 latest yolov8 elucidating key innovation difference and improvement across version in addition yolo framework field object detection and image processing developed several notable method technique r cnn region based convolutional neural network 1 and successor fast r cnn 2 and faster r cnn 3 played pivotal role in advancing accuracy object detection method rely on two stage process selective search generates region proposal and convolutional neural network classify and refine region another significant approach single shot multibox detector ssd 4 similar yolo focus on speed and efficiency by eliminating need for separate region proposal step additionally method like mask r nn 5 extended capability instance segmentation enabling precise object localization and pixel level segmentation development alongside others retinanet 6 and efficientdet 7 collectively contributed diverse landscape object detection algorithm method present unique tradeoff speed accuracy and complexity catering different application need and computational constraint arxiv 2304 00501v7 c cv 4 feb 2024published journal paper at machine learning and knowledge extraction yolov8 yolo na figure 1 timeline yolo version great review include 8 9 10 however review 8 cover yolov3 and 9 cover yolov4 leaving behind recent development paper different 10 show in depth architecture for yolo architecture presented and cover variation yolox pp yolos yolo transformer and yolo na paper begin by exploring foundational concept and architecture original yolo model set stage for subsequent advance in yolo family following dive refinement and enhancement introduced in version ranging yolov2 yolov8 improvement encompass various aspect network design loss function modification anchor box adaptation and input resolution scaling by examining development aim offer holistic understanding yolo framework evolution and implication for object detection in addition discussing specific advancement yolo version paper highlight tradeoff speed and accuracy emerged throughout framework development underscore importance considering context and requirement specific application selecting appropriate yolo model finally envision future direction yolo framework touching upon potential avenue for research and development shape ongoing progress real time object detection system 2 yolo application across diverse field yolo real time object detection capability invaluable in autonomous vehicle system enabling quick identification and tracking various object vehicle pedestrian 11 12 bicycle and obstacle 13 14 15 16 capability applied in numerous field including action recognition 17 in video sequence for surveillance 18 sport analysis 19 and human computer interaction 20 yolo model used in agriculture detect and classify crop 21 22 pest and disease 23 assisting in precision agriculture technique and automating farming process also adapted for face detection task in biometrics security and facial recognition system 24 25 in medical field yolo employed for cancer detection 26 27 skin segmentation 28 and pill identification 29 leading improved diagnostic accuracy and efficient treatment process in remote sensing used for object detection and classification in satellite and aerial imagery aiding in land use mapping urban planning and environmental monitoring 30 31 32 33 security system integrated yolo model for real time monitoring and analysis video feed allowing rapid detection suspicious activity 34 social distancing and face mask detection 35 model also applied in surface inspection detect defect and anomaly enhancing quality control in manufacturing and production process 36 37 38 in traffic application yolo model utilized for task license plate detection 39 and traffic sign recognition 40 contributing developing intelligent transportation system and traffic management solution employed in wildlife detection and monitoring identify endangered specie for biodiversity conservation and ecosystem management 41 lastly yolo widely used in robotic application 42 43 and object 2published journal paper at machine learning and knowledge extraction detection drone 44 45 figure 2 show bibliometric network visualization paper found in scopus word yolo in title and filtered by object detection keyword manually filtered paper related application figure 2 bibliometric network visualization main yolo application created 3 object detection metric and non maximum suppression nm average precision ap traditionally called mean average precision map commonly used metric for evaluating performance object detection model measure average precision across category providing single value compare different model coco dataset make distinction ap and map in rest paper refer metric ap in yolov1 and yolov2 dataset utilized for training and benchmarking pascal voc 2007 and voc 2012 46 however yolov3 onwards dataset used microsoft coco common object in context 47 ap calculated differently for datasets following section discus rationale behind ap and explain computed 3 1 ap work ap metric based on precision recall metric handling multiple object category and defining positive prediction using intersection union iou precision and recall precision measure accuracy model positive prediction while recall measure proportion actual positive case model correctly identifies often trade precision and recall for example increasing number detected object higher recall result in false positive lower precision account for trade ap metric incorporates precision recall curve plot precision 3published journal paper at machine learning and knowledge extraction recall for different confidence threshold metric provides balanced assessment precision and recall by considering area precision recall curve handling multiple object category object detection model must identify and localize multiple object category in image ap metric address by calculating category average precision ap separately and taking mean aps across category also called mean average precision approach ensures model performance evaluated for category individually providing comprehensive assessment model overall performance intersection union object detection aim accurately localize object in image by predicting bounding box ap metric incorporates intersection union iou measure ass quality predicted bounding box iou ratio intersection area union area predicted bounding box and ground truth bounding box see figure 3 measure overlap ground truth and predicted bounding box coco benchmark considers multiple iou threshold evaluate model performance at different level localization accuracy figure 3 intersection union iou iou calculated by dividing intersection two box by union box b example three different iou value for different box location 3 2 computing ap ap computed differently in voc and in coco datasets in section describe computed on dataset voc dataset dataset includes 20 object category compute ap in voc follow next step 1 for category calculate precision recall curve by varying confidence threshold model prediction 2 calculate category average precision ap using interpolated 11 point sampling precision recall curve 3 compute final average precision ap by taking mean aps across 20 category microsoft coco dataset dataset includes 80 object category and us complex method for calculating ap instead using 11 point interpolation us 101 point interpolation e computes precision for 101 recall threshold 0 1 in increment 0 01 also ap obtained by averaging multiple iou value instead one except for common ap metric called ap50 ap for single iou threshold 0 5 step for computing ap in coco following 1 for category calculate precision recall curve by varying confidence threshold model prediction 4published journal paper at machine learning and knowledge extraction 2 compute category average precision ap using 101 recall threshold 3 calculate ap at different intersection union iou threshold typically 0 5 0 95 step size 0 05 higher iou threshold requires accurate prediction considered true positive 4 for iou threshold take mean aps across 80 category 5 finally compute overall ap by averaging ap value calculated at iou threshold difference in ap calculation make hard directly compare performance object detection model across two datasets current standard us coco ap due fine grained evaluation well model performs at different iou threshold 3 3 non maximum suppression nm non maximum suppression nm post processing technique used in object detection algorithm reduce number overlapping bounding box and improve overall detection quality object detection algorithm typically generate multiple bounding box around object different confidence score nm filter redundant and irrelevant bounding box keeping accurate one algorithm 1 describes procedure figure 4 show typical output object detection model containing multiple overlapping bounding box and output nm algorithm 1 non maximum suppression algorithm require set predicted bounding box b confidence score iou threshold τ confidence threshold ensure set filtered bounding box f 1 2 filter box b 3 sort box bby confidence score in descending order 4 while 5 select box bwith highest confidence score 6 addbto set final box f b 7 remove bfrom set box b b 8 for remaining box rinbdo 9 calculate iou bandr b r 10 11 remove rfrom set box b r 12 end 13 end for 14 end while figure 4 non maximum suppression nm show typical output object detection model containing multiple overlapping box b show output nm ready start describing different yolo model 5published journal paper at machine learning and knowledge extraction 4 yolo look yolo by joseph redmon et al published in cvpr 2016 48 presented for first time real time end end approach for object detection name yolo stand for look referring fact able accomplish detection task single pas network opposed previous approach either used sliding window followed by classifier needed run hundred or thousand time per image or advanced method divided task two step first step detects possible region object or region proposal and second step run classifier on proposal also yolo used straightforward output based on regression predict detection output opposed fast r cnn 2 used two separate output classification for probability and regression for box coordinate 4 1 yolov1 work yolov1 unified object detection step by detecting bounding box simultaneously accomplish yolo divide input image and predicts bbounding box class along confidence for cdifferent class per grid element bounding box prediction consists five value pc bx by bh bw pcis confidence score for box reflects confident model box contains object and accurate box bxandbycoordinates center box relative grid cell and bhandbware height and width box relative full image output yolo tensor c optionally followed by non maximum suppression nm remove duplicate detection in original yolo paper author used pascal voc dataset 46 contains 20 class c 20 grid 7 and at 2classes per grid element b 2 giving prediction figure 5 show simplified output vector considering three by three grid three class and single class per grid for eight value in simplified case output yolo would yolov1 achieved average precision ap 63 4 on pascal voc2007 dataset figure 5 yolo output prediction figure depicts simplified yolo model three by three grid three class and single class prediction per grid element produce vector eight value 6published journal paper at machine learning and knowledge extraction table 1 yolo architecture architecture comprises 24 convolutional layer combining for channel reduction output fully connected layer generates grid 30 value for grid cell accommodate ten bounding box coordinate 2 box 20 category type filter size stride output conv 64 2 max pool 2 conv 192 1 max pool 2 128 1 conv 256 1 conv 256 1 conv 512 1 max pool 2 256 1 conv 512 1 conv 512 1 conv 1024 1 max pool 2 512 1 conv 1024 1 conv 1024 1 conv 1024 2 conv 1024 1 conv 1024 1 fc 4096 4096 dropout 0 5 4096 fc 7 4 2 yolov1 architecture yolov1 architecture comprises 24 convolutional layer followed by two fully connected layer predict bounding box coordinate and probability layer used leaky rectified linear unit activation 49 except for last one used linear activation function inspired by googlenet 50 and network in network 51 yolo us layer reduce number feature map and keep number parameter relatively low activation layer table 1 describes yolov1 architecture author also introduced lighter model called fast yolo composed nine convolutional layer 4 3 yolov1 training author pre trained first 20 layer yolo at resolution imagenet dataset 52 added last four layer randomly initialized weight and fine tuned model pascal voc 2007 and voc 2012 datasets 46 at resolution increase detail for accurate object detection for augmentation author used random scaling and translation at 20 input image size well random exposure and saturation upper end factor 1 5 in hsv color space yolov1 used loss function composed multiple sum squared error shown in figure 6 in loss function λcoord 5is scale factor give importance bounding box prediction and λnoobj 0 5is scale factor decrease importance box not contain object first two term loss represent localization loss computes error in predicted bounding box location x and size w h note error computed in box containing object represented by 1obj ij penalizing object present in grid cell third and fourth loss term represent confidence loss third term measure confidence error object detected in box 1obj ij and fourth term measure confidence error object not detected in box 1noobj ij since box 7published journal paper at machine learning and knowledge extraction empty loss weighted by λnoobj term final loss component classification loss measure squared error class conditional probability for class object appears in cell 1obj figure 6 yolo cost function includes localization loss for bounding box coordinate confidence loss for object presence or absence and classification loss for category prediction accuracy 4 4 yolov1 strength and limitation simple architecture yolo along novel full image one shot regression made much faster existing object detector allowing real time performance however while yolo performed faster object detector localization error larger compared state art method fast r cnn 2 three major cause limitation 1 could detect at two object class in grid cell limiting ability predict nearby object 8published journal paper at machine learning and knowledge extraction 2 struggled predict object aspect ratio not seen in training data 3 learned coarse object feature due sampling layer 5 yolov2 better faster and stronger yolov2 published in cvpr 2017 53 by joseph redmon and ali farhadi included several improvement original yolo make better keeping speed and also stronger detecting 9000 category improvement following 1 batch normalization on convolutional layer improved convergence and act regularizer reduce overfitting 2 high resolution classifier like yolov1 pre trained model imagenet at however time finetuned model for ten epoch on imagenet resolution improving network performance on higher resolution input 3 fully convolutional removed dense layer and used fully convolutional architecture 4 use anchor box predict bounding box use set prior box oranchor box box predefined shape used match prototypical shape object shown in figure 7 multiple anchor box defined for grid cell and system predicts coordinate and class for every anchor box size network output proportional number anchor box per grid cell 5 dimension cluster picking good prior box help network learn predict accurate bounding box author ran k mean clustering on training bounding box find good prior selected five prior box providing good tradeoff recall and model complexity 6 direct location prediction unlike method predicted offset 3 yolov2 followed philosophy and predicted location coordinate relative grid cell network predicts five bounding box for cell five value tx ty tw th and tois equivalent pcfrom yolov1 and final bounding box coordinate obtained shown in figure 8 7 finner grained feature yolov2 compared yolov1 removed one pooling layer obtain output feature map or grid input image yolov2 also us passthrough layer take map and reorganizes by stacking adjacent feature different channel instead losing via spatial subsampling generates feature map concatenated in channel dimension lower resolution map obtain feature map see table 2 for architectural detail 8 multi scale training since yolov2 not use fully connected layer input different size make yolov2 robust different input size author trained model randomly changing input size every ten batch figure 7 anchor box yolov2 defines multiple anchor box for grid cell improvement yolov2 achieved average precision ap 78 6 on pascal voc2007 dataset compared 63 4 obtained by yolov1 5 1 yolov2 architecture backbone architecture used by yolov2 called darknet 19 containing 19 convolutional layer and five max pooling layer similar architecture yolov1 inspired in network in network 51 using 9published journal paper at machine learning and knowledge extraction figure 8 bounding box prediction box center coordinate obtained predicted tx tyvalues passing sigmoid function and offset by location grid cell cx cy width and height final box use prior width pwand height phscaled by etwandethrespectively twandthare predicted by yolov2 convolution reduce number parameter in addition mentioned use batch normalization regularize and help convergence table 2 show entire darknet 19 backbone object detection head yolov2 predicts five bounding box five value and 20 class using pascal voc dataset object classification head replaces last four convolutional layer single convolutional layer 1000 filter followed by global average pooling layer and softmax 5 2 yolo9000 stronger yolov2 author introduced method for training joint classification and detection in paper used detection labeled data coco 47 learn bounding box coordinate and classification data imagenet increase number category detect during training combined datasets detection training image used backpropagates detection network and classification training image used backpropagates classification part architecture result yolo model capable detecting 9000 category hence name yolo9000 6 yolov3 yolov3 54 published in arxiv in 2018 by joseph redmon and ali farhadi included significant change and bigger architecture on par state art while keeping real time performance in following described change respect yolov2 1 bounding box prediction like yolov2 network predicts four coordinate for bounding box tx ty tw and th however time yolov3 predicts objectness score for bounding box using logistic regression score 1 for anchor box highest overlap ground truth and 0 for rest anchor box yolov3 opposed faster r cnn 3 assigns one anchor box ground truth object also anchor box assigned object incurs in classification loss but not localization loss or confidence loss 2 class prediction instead using softmax for classification used binary cross entropy train independent logistic classifier and pose problem multilabel classification change allows assigning multiple label box may occur on complex datasets 55 overlapping label for example object person and man 3 new backbone yolov3 feature larger feature extractor composed 53 convolutional layer residual connection section 6 1 describes architecture in detail 10published journal paper at machine learning and knowledge extraction table 2 yolov2 architecture darknet 19 backbone layer 1 23 plus detection head composed last four convolutional layer and passthrough layer reorganizes feature 17thoutput followed by concatenation 25thlayer final convolution generates grid 125 channel accommodate 25 prediction 5 coordinate 20 class for five bounding box num type filter size stride output 1 conv bn 32 1 2 max pool 2 3 conv bn 64 1 4 max pool 2 5 conv bn 128 1 6 conv bn 64 1 7 conv bn 128 1 8 max pool 2 9 conv bn 256 1 10 conv bn 128 1 11 conv bn 256 1 12 max pool 2 13 conv bn 512 1 14 conv bn 256 1 15 conv bn 512 1 16 conv bn 256 1 17 conv bn 512 1 18 max pool 2 19 conv bn 1024 1 20 conv bn 512 1 21 conv bn 1024 1 22 conv bn 512 1 23 conv bn 1024 1 24 conv bn 1024 1 25 conv bn 1024 1 26 reorg layer 17 27 concat 25 and 26 28 conv bn 1024 1 29 conv 125 1 4 spatial pyramid pooling spp although not mentioned in paper author also added backbone modified spp block 56 concatenates multiple max pooling output without subsampling stride 1 different kernel size k 1 5 9 13allowing larger receptive field version called yolov3 spp and best performed version improving ap 50by 2 7 5 multi scale prediction similar feature pyramid network 57 yolov3 predicts three box at three different scale section 6 2 describes multi scale prediction mechanism detail 6 bounding box prior like yolov2 author also use k mean determine bounding box prior anchor box difference in yolov2 used total five prior box per cell and in yolov3 used three prior box for three different scale 6 1 yolov3 architecture architecture backbone presented in yolov3 called darknet 53 replaced max pooling layer strided convolution and added residual connection in total contains 53 convolutional layer figure 9 show architecture detail darknet 53 backbone obtains top 1 and top 5 accuracy comparable resnet 152 but almost 11published journal paper at machine learning and knowledge extraction figure 9 yolov3 darknet 53 backbone architecture yolov3 composed 53 convolutional layer batch normalization and leaky relu activation also residual connection connect input convolution across whole network output architecture shown consists backbone not include detection head composed multi scale prediction 6 2 yolov3 multi scale prediction besides larger architecture essential feature yolov3 multi scale prediction e prediction at multiple grid size helped obtain finer detailed box and significantly improved prediction small object one main weakness previous version yolo multi scale detection architecture shown in figure 10 work follows first output marked y1is equivalent yolov2 output defines output second output y2is composed by concatenating output darknet 53 output feature map different size e upsampling operation concatenation finally using upsampling operation third output y3concatenates map map for coco dataset 80 category scale provides output tensor shape 4 1 80 size feature map or grid cell 3 indicates box per cell and 4 1 include four coordinate and objectness score 6 3 yolov3 result yolov3 released benchmark for object detection changed pascal voc microsoft coco 47 therefore on yolos evaluated in m coco dataset yolov3 spp achieved average precision ap 36 2 and ap 50of 60 6 at 20 fps achieving state art at time and 12published journal paper at machine learning and knowledge extraction figure 10 yolov3 multi scale detection architecture output darknet 53 backbone branched three different output marked y1 y2 and y3 increased resolution final predicted box filtered using non maximum suppression cbl convolution batchnorm leaky relu block comprise one convolution layer batch normalization and leaky relu re block comprise one cbl followed by two cbl structure residual connection shown in figure 9 7 backbone neck and head at time architecture object detector started described in three part backbone neck and head figure 11 show high level backbone neck and head diagram backbone responsible for extracting useful feature input image typically convolutional neural network cnn trained on large scale image classification task imagenet backbone capture hierarchical feature at different scale lower level feature e g edge and texture extracted in earlier layer and higher level feature e g object part and semantic information extracted in deeper layer neck intermediate component connects backbone head aggregate and refines feature extracted by backbone often focusing on enhancing spatial and semantic information across different scale neck may include additional convolutional layer feature pyramid network fpn 57 or mechanism improve representation feature head final component object detector responsible for making prediction based on feature provided by backbone and neck typically consists one or task specific subnetworks perform classification localization and recently instance segmentation and pose estimation head process feature neck provides generating prediction for object candidate in end post processing step non maximum suppression nm filter overlapping prediction and retains confident detection in rest yolo model describe architecture using backbone neck and head 8 yolov4 two year passed and new version yolo april 2020 alexey bochkovskiy chien yao wang and hong yuan mark liao released in arxiv paper for yolov4 58 at first felt odd different author presented new official version yolo however yolov4 kept yolo philosophy time open source single shot and darknet and improvement satisfactory community rapidly embrace version official yolov4 13published journal paper at machine learning and knowledge extraction figure 11 architecture modern object detector described backbone neck and head backbone usually convolutional neural network cnn extract vital feature image at different scale neck refines feature enhancing spatial and semantic information lastly head us refined feature make object detection prediction yolov4 tried find optimal balance by experimenting many change categorized bag freebie and bag special bag freebie method change training strategy and increase training cost but not increase inference time common data augmentation on hand bag special method slightly increase inference cost but significantly improve accuracy example method for enlarging receptive field 56 59 60 combining feature 61 57 62 63 and post processing 64 49 65 66 among others summarize main change yolov4 in following point enhanced architecture bag special bos integration author tried multiple architecture for backbone resnext50 67 efficientnet b3 68 and darknet 53 best performing architecture modification darknet 53 cross stage partial connection cspnet 69 and mish activation function 65 backbone see figure 12 for neck used modified version spatial pyramid pooling spp 56 yolov3 spp and multi scale prediction in yolov3 but modified version path aggregation network panet 70 instead fpn well modified spatial attention module sam 71 finally for detection head use anchor in yolov3 therefore model called cspdarknet53 panet spp cross stage partial connection csp added darknet 53 help reduce computation model while keeping accuracy spp block in yolov3 spp increase receptive field without affecting inference speed modified version panet concatenates feature instead adding in original panet paper bag freebie bof for advanced training approach apart regular augmenta tions random brightness contrast scaling cropping flipping and rotation author implemented mosaic augmentation combine four image single one allowing detection object outside usual context and also reducing need for large mini batch size for batch normalization for regularization used dropblock 72 work replacement dropout 73 but for convolutional neural network well class label smoothing 74 75 for detector added ciou loss 76 and cross mini bath normalization cmbn for collecting statistic entire batch instead single mini batch in regular batch normalization 77 adversarial training sat make model robust perturbation adversarial attack performed on input image create deception ground truth object not in image but keep original label detect correct object optimization genetic algorithm find optimal hyperparameters used for training use genetic algorithm on first 10 period and cosine annealing scheduler 78 alter learning rate during training start reducing learning rate slowly followed by quick reduction halfway training process ending slight reduction 14published journal paper at machine learning and knowledge extraction figure 12 yolov4 architecture for object detection module in diagram cmb convolution batch normalization mish activation cbl convolution batch normalization leaky relu upsampling spp spatial pyramid pooling and panet path aggregation network diagram inspired by 79 table 3 list final selection bofs and bos for backbone and detector evaluated on m coco dataset test dev 2017 yolov4 achieved ap 43 5 and ap 50of 65 7 at 50 fps on nvidia v100 9 yolov5 yolov5 80 released couple month yolov4 in 2020 by glen jocher founder and ceo ultralytics us many improvement described in yolov4 section but developed in pytorch instead darknet yolov5 incorporates ultralytics algorithm called autoanchor pre training tool check and adjusts anchor box ill fitted for dataset and training setting image size first applies k mean function dataset label generate initial condition for genetic evolution ge algorithm ge algorithm evolves anchor 1000 generation by default using ciou loss 76 and best possible recall fitness function figure 13 show detailed architecture yolov5 9 1 yolov5 architecture backbone modified cspdarknet53 start stem strided convolution layer large window size reduce memory and computational cost followed by convolutional layer extract relevant feature 15published journal paper at machine learning and knowledge extraction table 3 yolov4 final selection bag freebie bof and bag special bos bof method increase performance inference cost but longer training time on hand bos method slightly increase inference cost but significantly improve accuracy backbone detector bag freebie bag freebie data augmentation data augmentation mosaic mosaic cutmix self adversarial training regularization ciou loss dropblock cross mini batch normalization cmbn class label smoothing eliminate grid sensitivity multiple anchor for single ground truth cosine annealing scheduler optimal hyper parameteres random training shape bag special bag special mish activation mish activation cross stage partial connection spatial pyramid pooling block multi input weighted residual connection spatial attention module sam path aggregation network pan distance iou non maximum suppression input image sppf spatial pyramid pooling fast layer and following convolution layer process feature at various scale while upsample layer increase resolution feature map sppf layer aim speed computation network by pooling feature different scale fixed size feature map convolution followed by batch normalization bn and silu activation 81 neck us sppf and modified csp pan while head resembles yolov3 yolov5 us several augmentation mosaic copy paste 82 random affine mixup 83 hsv augmentation random horizontal flip well augmentation albumentations package 84 also improves grid sensitivity make stable runaway gradient yolov5 provides five scaled version yolov5n nano yolov5s small yolov5m medium yolov5l large and yolov5x extra large width and depth convolution module vary suit specific application and hardware requirement for instance yolov5n and yolov5s lightweight model targeted for low resource device while yolov5x optimized for high performance albeit at expense speed yolov5 released version at time writing v7 0 including yolov5 version capable classification and instance segmentation yolov5 open source and actively maintained by ultralytics 250 contributor and new improvement frequently yolov5 easy use train and deploy ultralytics provide mobile version for io and android and many integration for labeling training and deployment evaluated on m coco dataset test dev 2017 yolov5x achieved ap 50 7 image size 640 pixel using batch size 32 achieve speed 200 fps on nvidia v100 using larger input size 1536 pixel and test time augmentation tta yolov5 achieves ap 55 8 10 scaled yolov4 one year yolov4 author presented scaled yolov4 87 in cvpr 2021 differently yolov4 scaled yolov4 developed in pytorch instead darknet main novelty introduction scaling and scaling technique scaling mean producing model increase accuracy at expense lower speed on hand scaling entail producing model increase speed sacrificing accuracy in addition scaled model need le computing power and run on embedded system scaled architecture called yolov4 tiny designed for low end gpus and run at 46 fps on jetson tx2 or 440 fps on rtx2080ti achieving 22 ap on m coco 16published journal paper at machine learning and knowledge extraction figure 13 yolov5 architecture architecture us modified cspdarknet53 backbone stem followed by convolutional layer extract image feature spatial pyramid pooling fast sppf layer accelerates computation by pooling feature fixed size map convolution batch normalization and silu activation network neck us sppf and modified csp pan while head resembles yolov3 diagram based in 85 and 86 scaled model architecture called yolov4 large included three different size p5 p6 and p7 architecture designed for cloud gpu and achieved state art performance surpassing previous model 7 6 88 56 ap on m coco 17published journal paper at machine learning and knowledge extraction 11 yolor yolor 89 published in arxiv in may 2021 by research team yolov4 stand for learn one representation in paper author followed different approach developed multi task learning approach aim create single model for various task e g classification detection pose estimation by learning general representation and using sub network create task specific representation insight traditional joint learning method often lead suboptimal feature generation yolor aim overcome by encoding implicit knowledge neural network applied multiple task similar human use past experience approach new problem result showed introducing implicit knowledge neural network benefit task evaluated on m coco dataset test dev 2017 yolor achieved ap 55 4 and ap 50of 73 3 at 30 fps on nvidia v100 12 yolox yolox 90 published in arxiv in july 2021 by megvii technology developed in pytorch and using yolov3 ultralytics starting point five principal change anchor free architecture multiple positive decoupled head advanced label assignment and strong augmentation achieved state art result in 2021 optimal balance speed and accuracy 50 1 ap at 68 9 fps on tesla v100 in following describe five main change yolox respect yolov3 1 anchor free since yolov2 subsequent yolo version anchor based detector yolox inspired by anchor free state art object detector cornernet 91 centernet 92 and fcos 93 returned anchor free architecture simplifying training and decoding process anchor free increased ap by 0 9 point concerning yolov3 baseline 2 multi positive compensate for large imbalance lack anchor produced author use center sampling 93 assigned center positive approach increased ap by 2 1 point 3 decoupled head in 94 95 shown could misalignment classification confidence and localization accuracy due yolox separate two two head shown in fig 14 one for classification task and for regression task improving ap by 1 1 point and speeding model convergence 4 advanced label assignment in 96 shown ground truth label assignment could ambiguity box multiple object overlap and formulate assigning procedure optimal transport ot problem yolox inspired by work proposed simplified version called simota change increased ap by 2 3 point 5 strong augmentation yolox us mixup 83 and mosaic augmentation author found imagenet pretraining longer beneficial using augmentation strong augmentation increased ap by 2 4 point 13 yolov6 yolov6 97 published in arxiv in september 2022 by meituan vision ai department network design consists efficient backbone repvgg or cspstackrep block pan topology neck and efficient decoupled head hybrid channel strategy in addition paper introduces enhanced quantization technique using post training quantization and channel wise distillation resulting in faster and accurate detector overall yolov6 outperforms previous state art model on accuracy and speed metric yolov5 yolox and pp yoloe figure 15 show detailed architecture yolov6 main novelty model summarized 1 new backbone based on repvgg 98 called efficientrep us higher parallelism previous yolo backbone for neck use pan 70 enhanced repblocks 98 or cspstackrep 69 block for larger model and following yolox developed efficient decoupled head 2 label assignment using task alignment learning approach introduced in tood 100 18published journal paper at machine learning and knowledge extraction figure 14 difference yolov3 head and yolox decoupled head for level fpn used layer reduce feature channel 256 and added two parallel branch two convolution layer for class confidence classification and localization regression task iou branch added regression head 3 new classification and regression loss used classification varifocal loss 101 and siou 102 giou 103 regression loss 4 self distillation strategy for regression and classification task 5 quantization scheme for detection using repoptimizer 104 and channel wise distillation 105 helped achieve faster detector author provide eight scaled model yolov6 n yolov6 l6 evaluated on m coco dataset test dev 2017 largest model achieved ap 57 2 at around 29 fps on nvidia tesla t4 14 yolov7 yolov7 106 published in arxiv in july 2022 by author yolov4 and yolor at time surpassed known object detector in speed and accuracy in range 5 fps 160 fps like yolov4 trained using m coco dataset without pre trained backbone yolov7 proposed couple architecture change and series bag freebie increased accuracy without affecting inference speed training time figure 16 show detailed architecture yolov7 architecture change yolov7 efficient layer aggregation network e elan elan 108 strategy allows deep model learn and converge efficiently by controlling shortest longest gradient path yolov7 proposed e elan work for model unlimited stacked computational block e elan combine feature different group by shuffling and merging cardinality enhance network learning without destroying original gradient path scaling for concatenation based model scaling generates model different size by adjusting model attribute architecture yolov7 concatenation based architecture in standard scaling technique depth scaling cause ratio change input channel and output channel transition layer in turn lead decrease in hardware usage model yolov7 proposed new strategy for scaling concatenation based model in depth and width block scaled factor maintain optimal structure model bag freebie used in yolov7 include parameterized convolution like yolov6 architecture yolov7 also inspired by parameterized convolution repconv 98 however found identity connection in repconv 19published journal paper at machine learning and knowledge extraction figure 15 yolov6 architecture architecture us new backbone repvgg block 98 spatial pyramid pooling fast sppf and conv module similar yolov5 however yolov6 us decoupled head diagram based in 99 destroys residual in resnet 61 and concatenation in densenet 109 for reason removed identity connection and called repconvn label assignment for auxiliary head and fine label assignment for lead head lead head responsible for final output while auxiliary head assist training normalization in conv bn activation integrates mean and variance batch normalization bias and weight convolutional layer at inference stage knowledge inspired in yolor 89 moving average final inference model 14 1 comparison yolov4 and yolor in section highlight enhancement yolov7 compared previous yolo model developed by author compared yolov4 yolov7 achieved 75 reduction in parameter and 36 reduction in computation while simultaneously improving average precision ap by 1 5 in contrast yolov4 tiny yolov7 tiny managed reduce parameter and computation by 39 and 49 respec tively while maintaining ap lastly compared yolor yolov7 reduced number parameter and computation by 43 and 15 respectively along slight 0 4 increase in ap evaluated on m coco dataset test dev 2017 yolov7 e6 achieved ap 55 9 and ap 50of 73 5 input size 1280 pixel speed 50 fps on nvidia v100 20published journal paper at machine learning and knowledge extraction figure 16 yolov7 architecture change in architecture include elan block combine feature different group by shuffling and merging cardinality enhance model learning and modified repvgg without identity connection diagram based in 107 15 damo yolo damo yolo 110 published in arxiv in november 2022 by alibaba group inspired by current technology damo yolo included following 1 neural architecture search na used method called mae na 111 developed by alibaba find efficient architecture automatically 2 large neck inspired by giraffedet 112 cspnet 69 and elan 108 author designed neck work in real time called efficient repgfpn 3 small head author found large neck and small neck yield better performance and left one linear layer for classification and one for regression called approach zerohead 4 alignedota label assignment dynamic label assignment method ota 96 and tood 100 gained popularity due significant improvement static method however misalignment classification and regression remains problem partly because imbalance classification and regression loss address issue alignota method introduces focal loss 6 classification cost and us iou prediction and ground truth box soft label enabling selection aligned sample for target and solving problem global perspective 5 knowledge distillation proposed strategy consists two stage teacher guiding student in first stage and student fine tuning independently in second stage additionally incorporate two enhancement in distillation approach align module adapts student feature resolution teacher and channel wise dynamic temperature normalizes teacher and student feature reduce impact real value difference author generated scaled model named damo yolo tiny small medium best model achieving ap 50 0 at 233 fps on nvidia v100 16 yolov8 yolov8 113 released in january 2023 by ultralytics company developed yolov5 yolov8 provided five scaled version yolov8n nano yolov8s small yolov8m medium yolov8l large and yolov8x 21published journal paper at machine learning and knowledge extraction extra large yolov8 support multiple vision task object detection segmentation pose estimation tracking and classification 16 1 yolov8 architecture figure 17 show detailed architecture yolov8 yolov8 us similar backbone yolov5 change on csplayer called c2f module c2f module cross stage partial bottleneck two convolution combine high level feature contextual information improve detection accuracy yolov8 us anchor free model decoupled head independently process objectness classification and regression task design allows branch focus on task and improves model overall accuracy in output layer yolov8 used sigmoid function activation function for objectness score representing probability bounding box contains object us softmax function for class probability representing object probability belonging possible class yolov8 us ciou 76 and dfl 114 loss function for bounding box loss and binary cross entropy for classification loss loss improved object detection performance particularly dealing smaller object yolov8 also provides semantic segmentation model called yolov8 seg model backbone cspdarknet53 feature extractor followed by c2f module instead traditional yolo neck architecture c2f module followed by two segmentation head learn predict semantic segmentation mask for input image model similar detection head yolov8 consisting five detection module and prediction layer yolov8 seg model achieved state art result on various object detection and semantic segmentation benchmark while maintaining high speed and efficiency yolov8 run command line interface cli or also installed pip package in addition come multiple integration for labeling training and deploying evaluated on m coco dataset test dev 2017 yolov8x achieved ap 53 9 image size 640 pixel compared 50 7 yolov5 on input size speed 280 fps on nvidia a100 and tensorrt 17 pp yolo pp yolov2 and pp yoloe pp yolo model growing parallel yolo model described however decided group in single section because began yolov3 and gradually improving upon previous pp yolo version nevertheless model influential in evolution yolo pp yolo 88 similar yolov4 and yolov5 based on yolov3 published in arxiv in july 2020 by researcher baidu inc author used paddlepaddle 116 deep learning platform hence ppname following trend seen starting yolov4 pp yolo added ten existing trick improve detector accuracy keeping speed unchanged according author paper not intended introduce novel object detector but show build better detector step by step trick pp yolo us different one used in yolov4 and one overlap use different implementation change pp yolo concerning yolov3 1 resnet50 vd backbone replacing darknet 53 backbone architecture augmented de formable convolution 117 in last stage and distilled pre trained model higher classification accuracy on imagenet architecture called resnet5 vd dcn 2 larger batch size improve training stability went 64 192 along updated training schedule and learning rate 3 maintained moving average for trained parameter and use instead final trained value 4 dropblock applied fpn 5 iou loss added in another branch along l1 loss for bounding box regression 6 iou prediction branch added measure localization accuracy along iou aware loss during inference yolov3 multiplies classification probability and objectiveness score compute final detection pp yolo also multiplies predicted iou consider localization accuracy 7 grid sensitive approach similar yolov4 used improve bounding box center prediction at grid boundary 8 matrix nm 118 used run in parallel making faster traditional nm 22published journal paper at machine learning and knowledge extraction figure 17 yolov8 architecture architecture us modified cspdarknet53 backbone c2f module replaces csplayer used in yolov5 spatial pyramid pooling fast sppf layer accelerates computation by pooling feature fixed size map convolution batch normalization and silu activation head decoupled process objectness classification and regression task independently diagram based in 115 9 coordconv 119 used for fpn and on first convolution layer in detection head coordconv allows network learn translational invariance improving detection localization 10 spatial pyramid pooling used on top feature map increase receptive field backbone 17 1 pp yolo augmentation and preprocessing pp yolo used following augmentation and preprocessing 1 mixup training 83 weight sampled beta α β distribution α 1 5andβ 1 5 23published journal paper at machine learning and knowledge extraction 2 random color distortion 3 random expand 4 random crop and random flip probability 0 5 5 rgb channel z score normalization mean 0 485 0 456 0 406 and standard deviation 0 229 0 224 0 225 6 multiple image size evenly drawn 320 352 384 416 448 480 512 544 576 608 evaluated on m coco dataset test dev 2017 pp yolo achieved ap 45 9 and ap 50of 65 2 at 73 fps on nvidia v100 17 2 pp yolov2 pp yolov2 120 published in arxiv on april 2021 and added four refinement pp yolo increased performance 45 9 ap 49 5 ap at 69 fps on nvidia v100 change pp yolov2 concerning pp yolo following 1 backbone changed resnet50 resnet101 2 path aggregation network pan instead fpn similar yolov4 3 mish activation function unlike yolov4 and yolov5 applied mish activation function in detection neck keep backbone unchanged relu 4 larger input size help increase performance on small object expanded largest input size 608 768 and reduced batch size 24 12 image per gpu input size evenly drawn 320 352 384 416 448 480 512 544 576 608 640 672 704 736 768 5 modified iou aware branch modified calculation iou aware loss calculation using soft label format instead soft weight format 17 3 pp yoloe pp yoloe 121 published in arxiv in march 2022 added improvement upon pp yolov2 achieving performance 51 4 ap at 78 1 fps on nvidia v100 figure 18 show detailed architecture diagram main change pp yoloe concerning pp yolov2 1 anchor free following time trend driven by work 93 92 91 90 pp yoloe us anchor free architecture 2 new backbone and neck inspired by treenet 122 author modified architecture backbone and neck represblocks combining residual and dense connection 3 task alignment learning tal yolox first bring problem task misalignment classification confidence and location accuracy not agree in case reduce problem pp yoloe implemented tal proposed in tood 100 includes dynamic label assignment combined task alignment loss 4 efficient task aligned head et head different yolox classification and location head decoupled pp yoloe instead used single head based on tood improve speed and accuracy 5 varifocal vfl and distribution focal loss dfl vfl 101 weight loss positive sample using target score giving higher weight high iou prioritizes high quality sample during training similarly use iou aware classification score iacs target allowing for joint learning classification and localization quality leading consistency training and inference on hand dfl 114 extends focal loss discrete continuous label enabling successful optimization improved representation combine quality estimation and class prediction allows for accurate depiction flexible distribution in real data eliminating risk inconsistency like previous yolo version author generated multiple scaled model by varying width and depth backbone and neck model called pp yoloe small pp yoloe medium pp yoloe l large and pp yoloe x extra large 24published journal paper at machine learning and knowledge extraction figure 18 pp yoloe architecture backbone based on csprepresnet neck us path aggregation network and head us e layer form efficient task aligned head et head diagram based in 123 18 yolo na yolo na 124 released in may 2023 by deci company develops production grade model and tool build optimize and deploy deep learning model yolo na designed detect small object improve localization accuracy and enhance performance per compute ratio making suitable for real time edge device application in addition open source architecture available for research use novelty yolo na includes following aware module 125 called qsp and qci combine parameterization for 8 bit quantization minimize accuracy loss during post training quantization automatic architecture design using autonac deci proprietary na technology quantization method selectively quantize certain part model balance latency and accuracy instead standard quantization layer affected pre training regimen automatically labeled data self distillation and large datasets autonac system instrumental in creating yolo na versatile and accommodate task specific data environment for making inference and setting performance goal assist user in identifying suitable structure offer perfect blend precision and inference speed for particular use technology considers data and hardware and element involved in inference process compiler and quantization in addition repvgg block incorporated model architecture during na process for compatibility post training quantization ptq generated three architecture by varying depth and position qsp and qci block yolo na yolo nasm and yolo nasl l for small medium and large respectively figure 19 show model architecture for yolo nasl 25published journal paper at machine learning and knowledge extraction figure 19 yolo na architecture architecture found automatically via neural architecture search na system called autonac balance latency v throughput generated three architecture called yolo na small yolo nasm medium and yolo nasl large varying depth and position qsp and qci block figure show yolo nasl architecture model pre trained on objects365 126 contains two million image and 365 category coco dataset used generate pseudo label finally model trained original 118k train image coco dataset at writing three yolo na model released in fp32 fp16 and int8 precision achieving ap 52 2 on m coco 16 bit precision 19 yolo transformer rise transformer 127 taking deep learning task language and audio processing vision natural for transformer and yolo combined one first attempt at using transformer for object detection look at one sequence or yolos 128 turned pre trained vision transfomer vit 129 image classification object detection achieving 42 0 ap on m coco dataset change 26published journal paper at machine learning and knowledge extraction made vit two 1 replace one cl token used in classification one hundred det token for detection and 2 replace image classification loss in vit bipartite matching loss similar end end object detection transformer 130 figure 20 vit yolo architecture backbone mhsa darknet combine multi head self attention block mhsa dark block cross stage partial connection block cspdark block neck us bifpn aggregate feature different backbone level and head comprises five multi scale detection head many work combined transformer yolo related architecture tailored specific application for example zhang et al 131 motivated by robustness vision transformer occlusion perturbation and domain shift proposed vit yolo hybrid architecture combine csp darknet 58 and multi head self attention mhsa darknet in backbone along bidirectional feature pyramid network bifpn 7 for neck and multi scale detection head like yolov3 specific use case for object detection in drone image figure 20 show detailed architecture vit yolo msft yolo 132 add transformer based module backbone and detection head intending detect defect on steel surface nrt yolo 133 nested residual transformer try address problem tiny object in remote sensing image adding extra prediction head feature fusion layer and residual transformer module nrt yolo improved yolov5l by 5 4 in dota data set 134 in remote sensing application yolo sd 135 tried improve detection accuracy for small ship in synthetic aperture radar sar image started yolox 90 coupled multi scale convolution msc improve 27published journal paper at machine learning and knowledge extraction table 4 summary yolo architecture metric reported for yolo and yolov2 on voc2007 while rest reported on coco2017 na yolo model reported 16 bit precision version date anchor framework backbone ap yolo 2015 darknet darknet24 63 4 yolov2 2016 yes darknet darknet24 78 6 yolov3 2018 yes darknet darknet53 33 0 yolov4 2020 yes darknet cspdarknet53 43 5 yolov5 2020 yes pytorch yolov5cspdarknet 55 8 pp yolo 2020 yes paddlepaddle resnet50 vd 45 9 scaled yolov4 2021 yes pytorch cspdarknet 56 0 pp yolov2 2021 yes paddlepaddle resnet101 vd 50 3 yolor 2021 yes pytorch cspdarknet 55 4 yolox 2021 pytorch yoloxcspdarknet 51 2 pp yoloe 2022 paddlepaddle csprepresnet 54 7 yolov6 2022 pytorch efficientrep 52 5 yolov7 2022 pytorch yolov7backbone 56 8 damo yolo 2022 pytorch mae na 50 0 yolov8 2023 pytorch yolov8cspdarknet 53 9 yolo na 2023 pytorch na 52 2 detection at different scale and feature transformer module capture global feature author showed change improved accuracy yolo sd compared yolox in hrsid dataset 136 another interesting attempt combine yolo detection transformer detr 130 case deyo 137 comprising two stage yolov5 based model followed by detr like model first stage generates high quality query and anchor input second stage result show faster convergence time and better performance detr achieving 52 1 ap in coco detection benchmark 20 discussion paper examined 16 yolo version ranging original yolo model recent yolo na table 4 provides overview yolo version discussed table identify several key pattern original yolo model relatively simple and not employ anchor while state art relied on two stage detector anchor yolov2 incorporated anchor leading improvement in bounding box prediction accuracy trend persisted for five year yolox introduced anchor le approach achieved state art result since subsequent yolo version abandoned use anchor initially yolo developed using darknet framework subsequent version following suit however ultralytics ported yolov3 pytorch remaining yolo version developed using pytorch leading surge in enhancement another deep learning language utilized paddlepaddle open source framework initially developed by baidu backbone architecture yolo model undergone significant change time starting darknet architecture comprised simple convolutional and max pooling layer later model incorporated cross stage partial connection csp in yolov4 reparameterization in yolov6 and yolov7 and neural architecture search in damo yolo and yolo na while performance yolo model improved time worth noting often prioritize balancing speed and accuracy rather solely focusing on accuracy tradeoff essential yolo framework allowing for real time object detection across various application 20 1 tradeoff speed and accuracy yolo family object detection model consistently focused on balancing speed and accuracy aiming deliver real time performance without sacrificing quality detection result yolo framework evolved various iteration tradeoff recurring theme version seeking optimize competing objective differently in original yolo model primary focus on achieving high speed object 28published journal paper at machine learning and knowledge extraction detection model utilized single convolutional neural network cnn directly predict object location and class input image enabling real time processing however emphasis on speed led compromise in accuracy mainly dealing small object or object overlapping bounding box subsequent yolo version introduced refinement and enhancement address limitation while maintaining framework real time capability for instance yolov2 yolo9000 introduced anchor box and passthrough layer improve localization object resulting in higher accuracy in addition yolov3 enhanced model performance by employing multi scale feature extraction architecture allowing for better object detection across various scale tradeoff speed and accuracy became nuanced yolo framework evolved model like yolov4 and yolov5 introduced innovation new network backbone improved data augmentation technique and optimized training strategy development led significant gain in accuracy without drastically affecting model real time performance yolov5 official yolo model fine tuned tradeoff speed and accuracy offering different model scale suit specific application and hardware requirement for instance version often provide lightweight model optimized for edge device trading accuracy for reduced computational complexity and faster processing time figure 21 138 show comparison different model scale yolov5 yolov8 figure present comparative analysis different version yolo model in term complexity and performance left graph plot number parameter in million mean average precision map on coco validation set ranging iou threshold 50 95 illustrates clear trend increase in number parameter enhances model accuracy model includes various scale indicated by n nano small medium l large and x extra large right graph contrast inference latency on nvidia a100 gpu utilizing tensorrt fp16 map performance metric tradeoff inference speed and detection accuracy evident lower latency value indicating faster model inference typically result in reduced accuracy conversely model higher latency tend achieve better performance on coco map metric relationship pivotal for application real time processing crucial and choice model influenced by requirement balance speed and accuracy figure 21 performance comparison yolo object detection model left plot illustrates relationship model complexity measured by number parameter and detection accuracy coco map50 95 right plot show tradeoff inference speed latency on a100 tensorrt fp16 and accuracy for model model version represented by distinct color marker indicating size variant nano toextra plot taken 138 21 future yolo yolo framework continues evolve anticipate following trend and possibility shape future development 29published journal paper at machine learning and knowledge extraction incorporation latest technique researcher and developer continue refine yolo architecture by leveraging state art method in deep learning data augmentation and training technique ongoing innovation likely improve model performance robustness and efficiency benchmark evolution current benchmark for evaluating object detection model coco 2017 may eventually replaced by advanced and challenging benchmark mirror transition voc 2007 benchmark used in first two yolo version reflecting need for demanding benchmark model grow sophisticated and accurate proliferation yolo model and application yolo framework progress expect witness increase in number yolo model released year along corresponding expansion application framework becomes versatile and powerful likely employed in varied domain home appliance device autonomous car expansion new domain yolo model potential expand beyond object detection and segmentation exploring domain object tracking in video and 3d keypoint estimation anticipate yolo model transition multi modal framework incorporating vision and language video and sound processing model evolve may serve foundation for innovative solution catering broader spectrum computer vision and multimedia task adaptability diverse hardware yolo model span hardware platform iot device high performance computing cluster adaptability enable deploying yolo model in various context depending on application requirement and constraint in addition by tailoring model suit different hardware specification yolo made accessible and effective for user and industry 22 acknowledgment thank national council for science and technology conacyt for support national research system sni reference 1 r girshick j donahue darrell and j malik rich feature hierarchy for accurate object detection and semantic segmentation in proceeding ieee conference on computer vision and pattern recognition pp 2014 2 r girshick fast r cnn in proceeding ieee international conference on computer vision pp 2015 3 ren k r girshick and j sun faster r cnn towards real time object detection region proposal network advance in neural information processing system vol 28 2015 4 w liu anguelov erhan c szegedy reed c fu and c berg ssd single shot multibox detector in computer 2016 14th european conference amsterdam netherlands october 2016 proceeding part 14 pp springer 2016 5 k g gkioxari p dollár and r girshick mask r cnn in proceeding ieee international conference on computer vision pp 2017 6 lin p goyal r girshick k and p dollár focal loss for dense object detection in proceeding ieee international conference on computer vision pp 2017 7 tan r pang and q v le efficientdet scalable and efficient object detection in proceeding ieee cvf conference on computer vision and pattern recognition pp 2020 8 b bhavya sree v yashwanth bharadwaj and n neelima inter comparative survey on state art cnn yolo and ssd in intelligent manufacturing and energy sustainability proceeding icimes 2020 pp springer 2021 9 diwan g anirudh and j v tembhurne object detection using yolo challenge architectural successor datasets and application multimedia tool and application vol 82 6 pp 2023 10 hussain yolo v1 yolo v8 rise yolo and complementary nature toward digital manufacturing and industrial defect detection machine vol 11 7 p 677 2023 11 w lan j dang wang and wang pedestrian detection based on yolo network model in 2018 ieee international conference on mechatronics and automation icma pp ieee 2018 30published journal paper at machine learning and knowledge extraction 12 w hsu and w lin adaptive fusion multi scale yolo for pedestrian detection ieee access vol 9 pp 2021 13 benjumea teeti f cuzzolin and bradley yolo z improving small object detection in yolov5 for autonomous vehicle arxiv preprint arxiv 2112 11798 2021 14 n dazlee khalil abdul rahman and mutalib object detection for autonomous vehicle sensor based technology using yolo international journal intelligent system and application in engineering vol 10 1 pp 2022 15 liang h wu l zhen q hua garg g kaddoum hassan and k yu edge yolo real time intelligent object detection system based on edge cloud cooperation in autonomous vehicle ieee transaction on intelligent transportation system vol 23 12 pp 2022 16 q li x ding x wang l chen j son and j song detection and identification moving object at busy traffic road based on yolo v4 journal institute internet broadcasting and communication vol 21 1 pp 2021 17 shinde kothari and v gupta yolo based human action recognition and localization procedia computer science vol 133 pp 2018 18 h ashraf imran qahtani alsufyani almutiry mahmood attique and habib weapon detection for security and video surveillance using cnn and yolo v5s cmc comput mater contin vol 70 pp 2022 19 zheng and h zhang video analysis in sport by lightweight object detection network background sport industry development computational intelligence and neuroscience vol 2022 2022 20 h celik and h li fer yolo detection and classification based on facial expression in image and graphic 11th international conference icig 2021 haikou china august 2021 proceeding part 11 pp springer 2021 21 tian g yang z wang h wang e li and z liang apple detection during different growth stage in orchard using improved yolo v3 model computer and electronics in agriculture vol 157 pp 2019 22 wu lv jiang and h song using channel pruning based yolo v4 deep learning algorithm for real time and accurate detection apple flower in natural environment computer and electronics in agriculture vol 178 p 105742 2020 23 lippi n bonucci r f carpio contarini speranza and gasparri yolo based pest detection system for precision agriculture in 2021 29th mediterranean conference on control and automation med pp ieee 2021 24 w yang and z jiachun real time face detection based on yolo in 2018 1st ieee international conference on knowledge innovation and invention ickii pp ieee 2018 25 w chen h huang peng c zhou and c zhang yolo face real time face detector visual computer vol 37 pp 2021 26 al masni al antari j park g gi kim p rivera e valarezo choi han and kim simultaneous detection and classification breast mass in digital mammogram via deep learning yolo based cad system computer method and program in biomedicine vol 157 pp 2018 27 nie p sommella nil c liguori and j lundgren automatic detection melanoma yolo deep convolutional neural network in 2019 e health and bioengineering conference ehb pp ieee 2019 28 h ünver and e ayan skin lesion segmentation in dermoscopic image combination yolo and grabcut algorithm diagnostics vol 9 3 p 72 2019 29 l tan huangfu l wu and w chen comparison retinanet ssd and yolo v3 for real time pill identification bmc medical informatics and decision making vol 21 pp 2021 30 l cheng j li p duan and wang small attentional yolo model for landslide detection satellite remote sensing image landslide vol 18 8 pp 2021 31 pham l courtrai c friguet lefèvre and baussard yolo fine one stage detector small object various background in remote sensing image remote sensing vol 12 15 p 2501 2020 32 qing w liu l feng and w gao improved yolo network for free angle remote sensing target detection remote sensing vol 13 11 p 2171 2021 31published journal paper at machine learning and knowledge extraction 33 z zakria j deng r kumar khokhar j cai and j kumar multiscale and direction target detecting in remote sensing image via modified yolo v4 ieee journal selected topic in applied earth observation and remote sensing vol 15 pp 2022 34 p kumar narasimha swamy p kumar g purohit and k raju real time yolo based intelligent surveillance and monitoring system using jetson tx2 in data analytics and management proceeding icdam pp springer 2021 35 k bhambani jain and k sultanpure real time face mask and social distancing violation detection system using yolo in 2020 ieee bangalore humanitarian technology conference b htc pp ieee 2020 36 j li z su j geng and yin real time detection steel strip surface defect based on improved yolo detection network ifac papersonline vol 51 21 pp 2018 37 e n ukhwah e yuniarno and k suprapto asphalt pavement pothole detection using deep learning method based on yolo neural network in 2019 international seminar on intelligent technology and application isitia pp ieee 2019 38 du n pan z xu f deng shen and h kang pavement distress detection and classification based on yolo network international journal pavement engineering vol 22 13 pp 2021 39 r c chen et al automatic license plate recognition via sliding window darknet yolo deep learning image and vision computing vol 87 pp 2019 40 c dewi r c chen x jiang and h yu deep convolutional neural network for enhancing traffic sign recognition developed on yolo v4 multimedia tool and application vol 81 26 pp 2022 41 roy j bhaduri kumar and k raj wildect yolo efficient and robust computer vision based accurate object localization model for automated endangered wildlife detection ecological informatics vol 75 p 101919 2023 42 kulik and shtanko experiment neural net object detection system yolo on small training datasets for intelligent robotics in advanced technology in robotics and intelligent system proceeding itr 2019 pp springer 2020 43 h do real welfer de souza leite cuadros and f gamarra mobile robot navigation using object recognition software rgbd image and yolo algorithm applied artificial intelligence vol 33 14 pp 2019 44 sahin and ozer yolodrone improved yolo architecture for object detection in drone image in 2021 44th international conference on telecommunication and signal processing tsp pp ieee 2021 45 c chen z zheng xu guo feng w yao and lan yolo based uav technology review research and application drone vol 7 3 p 190 2023 46 everingham l van gool c k williams j winn and zisserman pascal visual object class voc challenge international journal computer vision vol 88 2 pp 2010 47 lin maire belongie j hay p perona ramanan p dollár and c l zitnick microsoft coco common object in context in european conference on computer vision pp springer 2014 48 j redmon divvala r girshick and farhadi look unified real time object detection in proceeding ieee conference on computer vision and pattern recognition pp 2016 49 l maas hannun ng et al rectifier nonlinearities improve neural network acoustic model in proc icml vol 30 p 3 atlanta georgia usa 2013 50 c szegedy w liu jia p sermanet reed anguelov erhan v vanhoucke and rabinovich going deeper convolution in proceeding ieee conference on computer vision and pattern recognition pp 2015 51 lin q chen and yan network in network arxiv preprint arxiv 1312 4400 2013 52 russakovsky j deng h su j krause satheesh z huang karpathy khosla bernstein et al imagenet large scale visual recognition challenge international journal computer vision vol 115 3 pp 2015 53 j redmon and farhadi yolo9000 better faster stronger in proceeding ieee conference on computer vision and pattern recognition pp 2017 54 j redmon and farhadi yolov3 incremental improvement arxiv preprint arxiv 1804 02767 2018 32published journal paper at machine learning and knowledge extraction 55 krasin duerig n alldrin v ferrari abu el haija kuznetsova h rom j uijlings popov veit et al openimages public dataset for large scale multi label and multi class image classification dataset available http github com openimages vol 2 3 p 18 2017 56 k x zhang ren and j sun spatial pyramid pooling in deep convolutional network for visual recognition ieee transaction on pattern analysis and machine intelligence vol 37 9 pp 2015 57 lin p dollár r girshick k b hariharan and belongie feature pyramid network for object detection in proceeding ieee conference on computer vision and pattern recognition pp 2017 58 bochkovskiy c wang and h liao yolov4 optimal speed and accuracy object detection arxiv preprint arxiv 2004 10934 2020 59 l c chen g papandreou kokkinos k murphy and l yuille deeplab semantic image segmentation deep convolutional net atrous convolution and fully connected crfs ieee transaction on pattern analysis and machine intelligence vol 40 4 pp 2017 60 liu huang et al receptive field block net for accurate and fast object detection in proceeding european conference on computer vision eccv pp 2018 61 k x zhang ren and j sun deep residual learning for image recognition in proceeding ieee conference on computer vision and pattern recognition pp 2016 62 b hariharan p arbeláez r girshick and j malik hypercolumns for object segmentation and fine grained localization in proceeding ieee conference on computer vision and pattern recognition pp 2015 63 q zhao sheng wang z tang chen l cai and h ling m2det single shot object detector based on multi level feature pyramid network in proceeding aaai conference on artificial intelligence vol 33 pp 2019 64 k x zhang ren and j sun delving deep rectifier surpassing human level performance on imagenet classification in proceeding ieee international conference on computer vision pp 2015 65 misra mish self regularized non monotonic neural activation function arxiv preprint arxiv 1908 08681 vol 4 2 pp 2019 66 n bodla b singh r chellappa and l davis soft object detection one line code inproceedings ieee international conference on computer vision pp 2017 67 xie r girshick p dollár z tu and k aggregated residual transformation for deep neural network inproceedings ieee conference on computer vision and pattern recognition pp 2017 68 tan and q le efficientnet rethinking model scaling for convolutional neural network in international conference on machine learning pp pmlr 2019 69 c wang h liao h wu p chen j w hsieh and h yeh cspnet new backbone enhance learning capability cnn in proceeding ieee cvf conference on computer vision and pattern recognition workshop pp 2020 70 liu l qi h qin j shi and j jia path aggregation network for instance segmentation in proceeding ieee conference on computer vision and pattern recognition pp 2018 71 woo j park j lee and kweon cbam convolutional block attention module in proceeding european conference on computer vision eccv pp 2018 72 g ghiasi lin and q v le dropblock regularization method for convolutional network advance in neural information processing system vol 31 2018 73 n srivastava g hinton krizhevsky sutskever and r salakhutdinov dropout simple way prevent neural network overfitting journal machine learning research vol 15 1 pp 2014 74 c szegedy v vanhoucke ioffe j shlens and z wojna rethinking inception architecture for computer vision in proceeding ieee conference on computer vision and pattern recognition pp 2016 75 islam naha rochan n bruce and wang label refinement network for coarse fine semantic segmentation arxiv preprint arxiv 1703 00551 2017 33published journal paper at machine learning and knowledge extraction 76 z zheng p wang w liu j li r ye and ren distance iou loss faster and better learning for bounding box regression in proceeding aaai conference on artificial intelligence vol 34 pp 2020 77 ioffe and c szegedy batch normalization accelerating deep network training by reducing internal covariate shift in international conference on machine learning pp pmlr 2015 78 loshchilov and f hutter sgdr stochastic gradient descent warm restarts arxiv preprint arxiv 1608 03983 2016 79 wang j zhao n ta x zhao xiao and h wei real time deep learning forest fire monitoring algorithm based on improved pruned kd model journal real time image processing vol 18 6 pp 2021 80 g jocher yolov5 by ultralytics http github com ultralytics yolov5 2020 accessed febru ary 30 2023 81 hendrycks and k gimpel gaussian error linear unit gelus arxiv preprint arxiv 1606 08415 2016 82 g ghiasi cui srinivas r qian lin e cubuk q v le and b zoph simple copy paste strong data augmentation method for instance segmentation in proceeding ieee cvf conference on computer vision and pattern recognition pp 2021 83 h zhang cisse n dauphin and lopez paz mixup beyond empirical risk minimization arxiv preprint arxiv 1710 09412 2017 84 buslaev v iglovikov e khvedchenya parinov druzhinin and kalinin albumentations fast and flexible image augmentation information vol 11 2 2020 85 contributor yolov5 by mmyolo http github com open mmlab mmyolo tree main configs yolov5 2023 accessed may 13 2023 86 ultralytics model structure http doc ultralytics com yolov5 tutorial architecture description 1 model structure 2023 accessed may 14 2023 87 c wang bochkovskiy and h liao scaled yolov4 scaling cross stage partial network in proceeding ieee cvf conference on computer vision and pattern recognition pp 2021 88 x long k deng g wang zhang q dang gao h shen j ren han e ding et al pp yolo effective and efficient implementation object detector arxiv preprint arxiv 2007 12099 2020 89 c wang h yeh and h liao learn one representation unified network for multiple task arxiv preprint arxiv 2105 04206 2021 90 z ge liu f wang z li and j sun yolox exceeding yolo series in 2021 arxiv preprint arxiv 2107 08430 2021 91 h law and j deng cornernet detecting object paired keypoints in proceeding european conference on computer vision eccv pp 2018 92 k duan bai l xie h qi q huang and q tian centernet keypoint triplet for object detection in proceeding ieee cvf international conference on computer vision pp 2019 93 z tian c shen h chen and fcos fully convolutional one stage object detection in proceeding ieee cvf international conference on computer vision pp 2019 94 g song liu and x wang revisiting sibling head in object detector in proceeding ieee cvf conference on computer vision and pattern recognition pp 2020 95 wu chen l yuan z liu l wang h li and fu rethinking classification and localization for object detection in proceeding ieee cvf conference on computer vision and pattern recognition pp 2020 96 z ge liu z li yoshie and j sun ota optimal transport assignment for object detection in proceeding ieee cvf conference on computer vision and pattern recognition pp 2021 97 c li l li h jiang k weng geng l li z ke q li cheng w nie et al yolov6 single stage object detection framework for industrial application arxiv preprint arxiv 2209 02976 2022 98 x ding x zhang n j han g ding and j sun repvgg making vgg style convnets great in proceeding ieee cvf conference on computer vision and pattern recognition pp 2021 99 contributor yolov6 by mmyolo http github com open mmlab mmyolo tree main configs yolov6 2023 accessed may 13 2023 34published journal paper at machine learning and knowledge extraction 100 c feng zhong gao r scott and w huang tood task aligned one stage object detection in 2021 ieee cvf international conference on computer vision iccv pp ieee computer society 2021 101 h zhang wang f dayoub and n sunderhauf varifocalnet iou aware dense object detector in proceeding ieee cvf conference on computer vision and pattern recognition pp 2021 102 z gevorgyan siou loss powerful learning for bounding box regression arxiv preprint arxiv 2205 12740 2022 103 h rezatofighi n tsoi j gwak sadeghian reid and savarese generalized intersection union metric and loss for bounding box regression in proceeding ieee cvf conference on computer vision and pattern recognition pp 2019 104 x ding h chen x zhang k huang j han and g ding parameterizing optimizers rather architecture arxiv preprint arxiv 2205 15242 2022 105 c shu liu j gao z yan and c shen channel wise knowledge distillation for dense prediction in proceeding ieee cvf international conference on computer vision pp 2021 106 c wang bochkovskiy and h liao yolov7 trainable bag freebie set new state art for real time object detector arxiv preprint arxiv 2207 02696 2022 107 contributor yolov7 by mmyolo http github com open mmlab mmyolo tree main configs yolov7 2023 accessed may 13 2023 108 c wang h liao and h yeh designing network design strategy gradient path analysis arxiv preprint arxiv 2211 04800 2022 109 g huang z liu l van der maaten and k q weinberger densely connected convolutional network in proceeding ieee conference on computer vision and pattern recognition pp 2017 110 x xu jiang w chen huang zhang and x sun damo yolo report on real time object detection design arxiv preprint arxiv 2211 15444 2022 111 alibaba tinynas http github com alibaba lightweight neural architecture search 2023 accessed march 18 2023 112 z tan j wang x sun lin h li et al giraffedet heavy neck paradigm for object detection in international conference on learning representation 2021 113 g jocher chaurasia and j qiu yolo by ultralytics http github com ultralytics ultralytics 2023 accessed february 30 2023 114 x li w wang l wu chen x hu j li j tang and j yang generalized focal loss learning qualified and distributed bounding box for dense object detection advance in neural information processing system vol 33 pp 2020 115 contributor yolov8 by mmyolo http github com open mmlab mmyolo tree main configs yolov8 2023 accessed may 13 2023 116 yu wu and h wang paddlepaddle open source deep learning platform industrial practice frontier data and domputing vol 1 1 pp 2019 117 j dai h qi xiong li g zhang h hu and wei deformable convolutional network in proceeding ieee international conference on computer vision pp 2017 118 w xinlong z rufeng k tao l lei and chunhua solov2 dynamic faster and stronger in proc nip 2020 119 r liu j lehman p molino f petroski e frank sergeev and j yosinski intriguing failing convolutional neural network and coordconv solution advance in neural information processing system vol 31 2018 120 x huang x wang w lv x bai x long k deng q dang han q liu x hu et al pp yolov2 practical object detector arxiv preprint arxiv 2104 10419 2021 121 xu x wang w lv q chang c cui k deng g wang q dang wei du et al pp yoloe evolved version yolo arxiv preprint arxiv 2203 16250 2022 122 l rao treenet lightweight one shot aggregation convolutional network arxiv preprint arxiv 2109 12342 2021 35published journal paper at machine learning and knowledge extraction 123 contributor pp yoloe by mmyolo http github com open mmlab mmyolo tree main configs ppyoloe 2023 accessed may 13 2023 124 r team yolo na by deci achieves state art performance on object detection using neural ar chitecture search http deci ai blog yolo na object detection foundation model 2023 accessed may 12 2023 125 x chu l li and b zhang make repvgg greater quantization aware approach arxiv preprint arxiv 2212 01593 2022 126 shao z li zhang c peng g yu x zhang j li and j sun objects365 large scale high quality dataset for object detection in proceeding ieee cvf international conference on computer vision pp 2019 127 vaswani n shazeer n parmar j uszkoreit l jones n gomez ł kaiser and polosukhin attention need advance in neural information processing system vol 30 2017 128 fang b liao x wang j fang j qi r wu j niu and w liu look at one sequence rethinking transformer in vision object detection advance in neural information processing system vol 34 pp 2021 129 dosovitskiy l beyer kolesnikov weissenborn x zhai unterthiner dehghani minderer g heigold gelly et al image worth 16x16 word transformer for image recognition at scale arxiv preprint arxiv 2010 11929 2020 130 n carion f massa g synnaeve n usunier kirillov and zagoruyko end end object detection transformer in european conference on computer vision pp springer 2020 131 z zhang x lu g cao yang l jiao and f liu vit yolo transformer based yolo for object detection inproceedings ieee cvf international conference on computer vision pp 2021 132 z guo c wang g yang z huang and g li msft yolo improved yolov5 based on transformer for detecting defect steel surface sensor vol 22 9 p 3467 2022 133 liu g z wang w li and h huang nrt yolo improved yolov5 based on nested residual transformer for tiny remote sensing object detection sensor vol 22 13 p 4953 2022 134 g xia x bai j ding z zhu belongie j luo datcu pelillo and l zhang dota large scale dataset for object detection in aerial image in proceeding ieee conference on computer vision and pattern recognition pp 2018 135 wang gao l zhou r liu h zhang j liu jia and j qian yolo sd small ship detection in sar image by multi scale convolution and feature transformer module remote sensing vol 14 20 p 5268 2022 136 wei x zeng q qu wang h su and j shi hrsid high resolution sar image dataset for ship detection and instance segmentation ieee access vol 8 pp 2020 137 h ouyang deyo detr yolo for step by step object detection arxiv preprint arxiv 2211 06588 2022 138 ultralytics yolov8 documentation http doc ultralytics com model yolov8 2023 accessed january 7 2024 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yasir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yasir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yasir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure you download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def balanced_text_cleaning(text):\n",
    "    # Initialize Lemmatizer and Stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Define additional stopwords to retain context (Optional)\n",
    "    retained_stopwords = {'and', 'or', 'but', 'not', 'because', 'while', 'during', 'for', 'in', 'on', 'at', 'by'}\n",
    "    stop_words -= retained_stopwords\n",
    "    \n",
    "    # Step 1: Case Normalization\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Step 2: Remove Non-essential Punctuation (keep sentence structure intact)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    \n",
    "    # Step 3: Tokenize Text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Step 4: Remove Stopwords and Perform Lemmatization\n",
    "    cleaned_tokens = [\n",
    "        lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word.isalnum()\n",
    "    ]\n",
    "    \n",
    "    # Step 5: Join Tokens Back into Text\n",
    "    cleaned_text = \" \".join(cleaned_tokens)\n",
    "    \n",
    "    # Step 6: Whitespace Cleanup\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# Example Input\n",
    "text = pdf_text\n",
    "\n",
    "# Cleaned Output\n",
    "cleaned_text = balanced_text_cleaning(text)\n",
    "print(\"Cleaned Text:\\n\", cleaned_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
